import streamlit as st
import pandas as pd
import plotly.express as px
import FinanceDataReader as fdr
import requests
import urllib3
from io import StringIO, BytesIO
from datetime import datetime, timedelta, date
import yfinance as yf
import feedparser
import numpy as np
import pytz
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import plotly.express as px
import seaborn as sns
from collections import Counter
import re

# [í•„ìˆ˜] ê°™ì€ í´ë”ì˜ etf.pyì—ì„œ í´ë˜ìŠ¤ ì„í¬íŠ¸
try:
    from etf import ActiveETFMonitor
    try:
        from etf_kiwoom import KiwoomETFMonitor
    except ImportError:
        KiwoomETFMonitor = None
except ImportError:
    st.error("âš ï¸ 'etf.py' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê°™ì€ í´ë”ì— ë„£ì–´ì£¼ì„¸ìš”.")
    st.stop()

# [NEW] Helper for Earnings Idio Score
import plotly.graph_objects as go
try:
    import logic_idio
except ImportError:
    logic_idio = None

# [NEW] Crawler Logic Import
import logic_crawler

# [NEW] Earnings Logic Import
try:
    from logic_earnings import get_naver_consensus_change
except ImportError:
     pass # handling later

# ë³´ì•ˆ ì¸ì¦ì„œ ê²½ê³  ë¬´ì‹œ ë° SSL ê²€ì¦ ìš°íšŒ (Global Patch)
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
original_request = requests.Session.request
def patched_request(self, method, url, *args, **kwargs):
    kwargs['verify'] = False
    return original_request(self, method, url, *args, **kwargs)
requests.Session.request = patched_request


# ---------------------------------------------------------
# 1. í˜ì´ì§€ ì„¤ì •
# ---------------------------------------------------------
st.set_page_config(
    page_title="MAS Strategy Dashboard",
    page_icon="mirae_icon.png",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ---------------------------------------------------------
# 2. ë°ì´í„° ìˆ˜ì§‘ ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ---------------------------------------------------------

@st.cache_data(ttl=600)
def fetch_market_data():
    """ì‹œì¥ í•µì‹¬ ì§€í‘œ ìˆ˜ì§‘"""
    tickers = {
        "KOSPI": "^KS11", "S&P500": "^GSPC", "Nasdaq": "^IXIC", 
        "USD/KRW": "KRW=X", "US 10Y": "^TNX", "WTI Oil": "CL=F"
    }
    data_dict = {}
    history_dict = {}
    
    for name, code in tickers.items():
        try:
            obj = yf.Ticker(code)
            hist = obj.history(period="1y")
            if not hist.empty:
                current = hist['Close'].iloc[-1]
                prev = hist['Close'].iloc[-2]
                pct_change = ((current - prev) / prev) * 100
                hist['MA20'] = hist['Close'].rolling(window=20).mean()
                trend = "ìƒìŠ¹" if current > hist['MA20'].iloc[-1] else "í•˜ë½"
                data_dict[name] = {"price": current, "pct_change": pct_change, "trend": trend}
                history_dict[name] = hist
        except: continue
    return data_dict, history_dict

def to_excel(df_new, df_inc, df_dec, df_all, date):
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df_new.to_excel(writer, index=False, sheet_name='ì‹ ê·œí¸ì…')
        df_inc.to_excel(writer, index=False, sheet_name='ë¹„ì¤‘í™•ëŒ€')
        df_dec.to_excel(writer, index=False, sheet_name='ë¹„ì¤‘ì¶•ì†Œ')
        df_all.to_excel(writer, index=False, sheet_name='ì „ì²´í¬íŠ¸í´ë¦¬ì˜¤')
    return output.getvalue()



def fetch_yahoo_news(tickers):
    """Yahoo Finance ë‰´ìŠ¤ ìˆ˜ì§‘ (ë” ì‹ ë¢°ë„ ë†’ì€ ì†ŒìŠ¤)"""
    news_items = []
    try:
        # ì—¬ëŸ¬ í‹°ì»¤ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬
        for ticker in tickers:
            stock = yf.Ticker(ticker)
            news = stock.news
            if news:
                for n in news:
                    # YF ë‰´ìŠ¤ êµ¬ì¡°: title, link, providerPublishTime, publisher
                    pub_time = n.get('providerPublishTime', 0)
                    dt = datetime.fromtimestamp(pub_time)
                    
                    news_items.append({
                        "title": n.get('title', ''),
                        "link": n.get('link', ''),
                        "published_dt": dt,
                        "published": dt.strftime("%Y-%m-%d %H:%M"),
                        "source": f"Yahoo ({n.get('publisher', 'Unknown')})"
                    })
    except Exception as e:
        # st.error(f"Yahoo News Error: {e}") # ë””ë²„ê¹…ìš©
        pass
        
    return news_items

@st.cache_data(ttl=3600)
def fetch_trending_tickers():
    """Yahoo Finance Trending Tickers ê°€ì ¸ì˜¤ê¸°"""
    trending = []
    try:
        # Yahoo Finance Trending Endpoint (US Region)
        url = "https://query1.finance.yahoo.com/v1/finance/trending/US?count=10"
        headers = {'User-Agent': 'Mozilla/5.0'}
        resp = requests.get(url, headers=headers, verify=False) # SSL false per user env
        data = resp.json()
        
        result = data['finance']['result'][0]['quotes']
        for item in result:
             symbol = item['symbol']
             trending.append(symbol)
             
    except Exception as e:
        pass
    return trending

@st.cache_data(ttl=3600)
def fetch_kdi_keywords():
    """KDI ê²½ì œ ì •ë³´ ì„¼í„° - ê²½ì œ í‚¤ì›Œë“œ íŠ¸ë Œë“œ í¬ë¡¤ë§"""
    keywords = []
    try:
        url = "https://eiec.kdi.re.kr/bigdata/issueTrend.do"
        headers = {'User-Agent': 'Mozilla/5.0'}
        # KDI ì‚¬ì´íŠ¸ëŠ” SSL ê²€ì¦ì´ í•„ìš”í•  ìˆ˜ ìˆìœ¼ë‚˜, ì‚¬ìš©ì í™˜ê²½ ê³ ë ¤ False
        resp = requests.get(url, headers=headers, verify=False)
        html = resp.text
        
        # ì •ê·œì‹ìœ¼ë¡œ [í‚¤ì›Œë“œ](javascript:;) íŒ¨í„´ ì¶”ì¶œ
        # ì˜ˆ: [ì›ë‹¬ëŸ¬í™˜ìœ¨](javascript:;)
        # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•´ ë¦¬ìŠ¤íŠ¸ ëŒ€ì‹  ì§‘í•© ì‚¬ìš© í›„ ë‹¤ì‹œ ë¦¬ìŠ¤íŠ¸ë¡œ
        found = re.findall(r'\[(.*?)\]\(javascript:;\)', html)
        
        # ìˆœì„œ ìœ ì§€ë¥¼ ìœ„í•´ dict.fromkeys ì‚¬ìš© (Python 3.7+)
        keywords = list(dict.fromkeys(found))
        
        # ìƒìœ„ 20ê°œë§Œ
        return keywords[:20]
        
    except Exception as e:
        # st.error(f"KDI Fetch Error: {e}")
        return []

@st.cache_data(ttl=3600)
def fetch_global_events():
    """ì „ì²´ ì‹œì¥ í•µì‹¬ ì´ë²¤íŠ¸ ìˆ˜ì§‘ (Google News + Yahoo Finance)"""
    market_news = []
    
    # 1. Yahoo Finance (ì‹ ë¢°ì˜¤ ì†ŒìŠ¤ ìš°ì„  - SPY, QQQ, NVDA)
    market_news.extend(fetch_yahoo_news(["SPY", "QQQ", "^DJI"]))
    
    # 2. Google News (ë³´ì¡°)
    # ê´‘ë²”ìœ„í•œ ì‹œì¥ í‚¤ì›Œë“œ
    query = "stock market live updates Fed CPI inflation earnings report when:3d"
    encoded = requests.utils.quote(query)
    url = f"https://news.google.com/rss/search?q={encoded}&hl=en-US&gl=US&ceid=US:en"
    
    try:
        feed = feedparser.parse(url)
        for e in feed.entries:
            # ë‚ ì§œ íŒŒì‹±
            if hasattr(e, 'published_parsed') and e.published_parsed:
                dt = datetime(*e.published_parsed[:6])
            else:
                dt = datetime.now()

            market_news.append({
                "title": e.title,
                "link": e.link,
                "published": e.published,
                "published_dt": dt, # ì •ë ¬ìš©
                "source": e.source.title if hasattr(e, 'source') else "News"
            })
    except: pass
    
    # ì¤‘ë³µ ì œê±° (Link ê¸°ì¤€) & ì •ë ¬
    seen_links = set()
    unique_news = []
    for n in market_news:
        if n['link'] not in seen_links:
            unique_news.append(n)
            seen_links.add(n['link'])
            
    # ìµœì‹ ìˆœ ì •ë ¬
    unique_news.sort(key=lambda x: x['published_dt'], reverse=True)
    
    return unique_news[:7] # Top 7 (ì•¼í›„ ì¶”ê°€ë¡œ ê°œìˆ˜ ëŠ˜ë¦¼)

@st.cache_data(ttl=3600)
def fetch_ib_news(bank_name):
    """ì£¼ìš” IBë“¤ì˜ ìµœì‹  ë§ˆì¼“ ì½”ë©˜íŠ¸ ìˆ˜ì§‘ (Google News + Yahoo Finance)"""
    ib_news = []
    
    # 1. Yahoo Finance (í‹°ì»¤ ë§¤í•‘)
    ticker_map = {
        "JP Morgan": "JPM",
        "Goldman Sachs": "GS",
        "Morgan Stanley": "MS"
    }
    
    if bank_name in ticker_map:
        ib_news.extend(fetch_yahoo_news([ticker_map[bank_name]]))

    # 2. Google News RSS
    # ê²€ìƒ‰ì–´ ìµœì í™”: "BankName market outlook 2025" or "BankName stock strategy" relative to last 30 days
    query = f"{bank_name} market outlook strategy forecast when:30d"
    encoded = requests.utils.quote(query)
    url = f"https://news.google.com/rss/search?q={encoded}&hl=en-US&gl=US&ceid=US:en"
    
    try:
        feed = feedparser.parse(url)
        for e in feed.entries:
            # ë‚ ì§œ íŒŒì‹±
            if hasattr(e, 'published_parsed') and e.published_parsed:
                dt = datetime(*e.published_parsed[:6])
            else:
                dt = datetime.now()

            ib_news.append({
                "title": e.title,
                "link": e.link,
                "published": e.published,
                "published_dt": dt,
                "source": e.source.title if hasattr(e, 'source') else "News"
            })
    except: pass
    
    # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
    seen_titles = set()
    unique_news = []
    for n in ib_news:
        # ì œëª©ì´ ë„ˆë¬´ ë¹„ìŠ·í•˜ë©´ ì¤‘ë³µ ì²˜ë¦¬ (ê°„ë‹¨í•œ ë¡œì§)
        title_summary = n['title'][:30]
        if title_summary not in seen_titles:
            unique_news.append(n)
            seen_titles.add(title_summary)
            
    # ìµœì‹ ìˆœ ì •ë ¬
    unique_news.sort(key=lambda x: x['published_dt'], reverse=True)
    
    return unique_news[:5] # Top 5

def get_news_tags(title):
    """ë‰´ìŠ¤ ì œëª© ê¸°ë°˜ íƒœê·¸ ìƒì„± (NLP-lite)"""
    title_lower = title.lower()
    tags = []
    
    # 1. Momentum (Positive)
    if any(k in title_lower for k in ["upgrade", "buy", "bull", "overweight", "raise", "top pick", "growth", "positive", "hike"]):
        tags.append(("ğŸš€ Momentum", "#FFEAEA", "#FF0000")) # Text, BG, Color
        
    # 2. Risk (Negative)
    if any(k in title_lower for k in ["downgrade", "sell", "bear", "underweight", "cut", "risk", "warn", "negative", "slow", "recession"]):
        tags.append(("âš ï¸ Risk", "#EAEFFF", "#0000FF"))
        
    # 3. Key Event (Neutral/Impact)
    if any(k in title_lower for k in ["fed", "rate", "cpi", "inflation", "earnings", "policy", "meeting", "tech", "ai "]):
        tags.append(("ğŸ“¢ Event", "#F2F2F2", "#333333"))
        
    return tags

def calculate_super_theme(df, ref_date=None):
    """ìŠˆí¼í…Œë§ˆ ETF ìˆ˜ìµë¥  ë° ë³€ë™ì„± ê³„ì‚° (FDR ì‚¬ìš©)"""
    results = []
    
    if ref_date is None:
        ref_date = datetime.now()
    
    end_date_str = ref_date.strftime("%Y-%m-%d")
    # 60D ë³€ë™ì„± ê³„ì‚°ì„ ìœ„í•´ ë„‰ë„‰í•œ ë°ì´í„° í•„ìš” (ì•½ 4~5ê°œì›”)
    start_date_str = (ref_date - timedelta(days=150)).strftime("%Y-%m-%d")
    
    for i, row in df.iterrows():
        ticker = str(row['Ticker']).strip()
        if ticker.endswith('.KS'): ticker = ticker.replace('.KS', '')
        
        try:
            hist = fdr.DataReader(ticker, start_date_str, end_date_str)
            
            if not hist.empty:
                curr = hist['Close'].iloc[-1]
                
                # Returns (Round to 1 decimal)
                ret_1d = ((curr - hist['Close'].iloc[-2]) / hist['Close'].iloc[-2] * 100) if len(hist) >= 2 else 0
                ret_5d = ((curr - hist['Close'].iloc[-6]) / hist['Close'].iloc[-6] * 100) if len(hist) >= 6 else 0
                # 1M = 20 trading days
                ret_1m = ((curr - hist['Close'].iloc[-21]) / hist['Close'].iloc[-21] * 100) if len(hist) >= 21 else 0
                
                # VOL_60D Calculation (Annualized Volatility of last 60 days)
                # Formula: StdDev(Daily Returns of last 60 days) * sqrt(252) * 100
                if len(hist) > 60:
                    recent_60 = hist['Close'].iloc[-61:] # Get 61 points to have 60 returns
                    daily_ret = recent_60.pct_change().dropna()
                    vol_60d = daily_ret.std() * (252 ** 0.5) * 100
                else:
                    vol_60d = 0

                # Get Score from Input DF if exists, else 0
                score = row.get('Score', 0)
                
                results.append({
                    "Ticker": row['Ticker'],
                    "Name": row['Name'],
                    "Theme": row['Theme'],
                    "Score": score, # Scoring provided by user
                    "1D": round(ret_1d, 1),
                    "5D": round(ret_5d, 1),
                    "1M": round(ret_1m, 1),
                    "VOL_60D": round(vol_60d, 1)
                })
            else:
                 st.warning(f"{ticker}: ë°ì´í„° ì—†ìŒ")
        except Exception as e:
            st.error(f"{ticker} ì—ëŸ¬: {e}")
    
    if not results:
        return pd.DataFrame(columns=["Ticker", "Name", "Theme", "Score", "1D", "5D", "1M", "VOL_60D"])
    
    return pd.DataFrame(results)

def calculate_super_stock(df, ref_date=None):
    """ìŠˆí¼ìŠ¤íƒ ë°ì´í„° ê³„ì‚° (Mkt.Cap, Score, Multiples í¬í•¨)"""
    results = []
    
    if ref_date is None:
        ref_date = datetime.now()
        
    end_date_str = ref_date.strftime("%Y-%m-%d")
    start_date_str = (ref_date - timedelta(days=10)).strftime("%Y-%m-%d")

    for i, row in df.iterrows():
        ticker = str(row['Ticker']).strip()
        if ticker.endswith('.KS'): ticker = ticker.replace('.KS', '')
        
        try:
            # FDR is used mainly to verify ticker is active, or we could skip if we trust input.
            # But let's fetch to ensure we're aligned with market.
            # Actually, user wants "Organize by MktCap, Score...". 
            # If we don't fetch price, we can't show "Change". 
            # But user request focused on "Mkt.Cap, score, PER, PEG".
            # Input DF already has these from universe.xslx via `update_universe.py`.
            
            # Fetch price just for validity check
            # hist = fdr.DataReader(ticker, start_date_str, end_date_str)
            
            results.append({
                "Ticker": row['Ticker'],
                "Name": row['Name'],
                "Sector": row['Sector'],
                "Mkt.Cap($bn)": row.get('MktGap', 0), # MktGap column from make_universe
                "Score": row.get('Score', 0),
                "PER": row.get('PER', 0),
                "PEG": row.get('PEG', 0)
            })
        except: pass
        
    return pd.DataFrame(results)

@st.cache_data(ttl=86400)
def fetch_statcounter_data(metric="search_engine", device="desktop+mobile+tablet+console", region="ww", from_year="2019", from_month="01", to_year=None, to_month=None):
    """StatCounter ë°ì´í„° ìˆ˜ì§‘ (CSV Direct)"""
    import requests
    import io
    from datetime import datetime
    
    # to_year/to_monthê°€ ì—†ìœ¼ë©´ í˜„ì¬ ì‹œê°„ ê¸°ì¤€
    if to_year is None or to_month is None:
        now = datetime.now()
        to_year = now.year
        to_month = now.month
    
    base_url = "https://gs.statcounter.com/chart.php"
    
    # device íŒŒë¼ë¯¸í„° ì²˜ë¦¬
    # device_hidden ê°’ ì„¤ì • (StatCounterëŠ” device_hiddenì„ ì£¼ë¡œ ì‚¬ìš©)
    device_val = device
    
    # metric ì„¤ì •
    if metric == "search_engine":
        stat_type_hidden = "search_engine"
        stat_type_label = "Search Engine"
    elif metric == "os":
        stat_type_hidden = "os_combined"
        stat_type_label = "OS Market Share"
    elif metric == "browser":
        stat_type_hidden = "browser"
        stat_type_label = "Browser"
        
    params = {
        "device": device, # Label text but utilizing same val for simplicity or need map? 
        # Actually StatCounter url uses 'device' param for label and 'device_hidden' for value.
        # But 'device' param in getting csv might be loose. Let's use correct hidden val.
        "device_hidden": device_val, 
        "multi-device": "true",
        "statType_hidden": stat_type_hidden,
        "region_hidden": region,
        "granularity": "monthly",
        "statType": stat_type_label,
        "region": "Worldwide",
        "fromInt": f"{from_year}{from_month}",
        "toInt": f"{to_year}{to_month:02d}",
        "fromMonthYear": f"{from_year}-{from_month}",
        "toMonthYear": f"{to_year}-{to_month:02d}",
        "csv": "1"
    }
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }
    
    try:
        response = requests.get(base_url, params=params, headers=headers, verify=False)
        if response.status_code == 200:
            df = pd.read_csv(io.StringIO(response.text))
            # ë‚ ì§œë¥¼ YYYY-MM í˜•ì‹ì˜ ë¬¸ìì—´ë¡œ ë³€í™˜
            df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m')
            df.set_index('Date', inplace=True)
            return df
        else:
            return pd.DataFrame()
    except Exception as e:
        st.error(f"ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
        return pd.DataFrame()

def process_search_engine_data(df):
    """Google, Bing, Yahoo, Other 4íŒŒì „ìœ¼ë¡œ ì •ë¦¬"""
    if df.empty:
        return df
        
    # CSV header might be 'bing' or 'Bing', 'Yahoo!' or 'Yahoo'
    cols = df.columns
    
    # Bing ì´ë¦„ í™•ì¸
    bing_col = 'bing' if 'bing' in cols else 'Bing'
    # Yahoo ì´ë¦„ í™•ì¸
    yahoo_col = 'Yahoo!' if 'Yahoo!' in cols else 'Yahoo'
    
    final_targets = ['Google', bing_col, yahoo_col]
    
    # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
    valid_targets = [c for c in final_targets if c in cols]
    
    # Other ê³„ì‚°
    other_cols = [c for c in cols if c not in valid_targets]
    
    df_processed = df[valid_targets].copy()
    if other_cols:
        df_processed['Other'] = df[other_cols].sum(axis=1)
    
    # ì´ë¦„ í†µì¼
    rename_map = {}
    if yahoo_col in df_processed.columns:
        rename_map[yahoo_col] = 'Yahoo'
    if bing_col in df_processed.columns:
        rename_map[bing_col] = 'Bing'
        
    if rename_map:
        df_processed.rename(columns=rename_map, inplace=True)
        
    # ìš”ì²­ëœ ìˆœì„œë¡œ ì •ë ¬: Google, Yahoo, Other, Bing
    desired_order = ['Google', 'Yahoo', 'Other', 'Bing']
    # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ í•„í„°ë§í•˜ì—¬ ìˆœì„œ ì ìš©
    final_order = [c for c in desired_order if c in df_processed.columns]
    
    return df_processed[final_order]

# ë°ì´í„° ë¡œë“œ
macro_metrics, macro_histories = fetch_market_data()

# ---------------------------------------------------------
# 3. ì‚¬ì´ë“œë°” êµ¬ì„±
# ---------------------------------------------------------
with st.sidebar:
    import os
    if os.path.exists("mirae_icon.png"):
        st.image("mirae_icon.png", use_container_width=True)
    else:
        st.title("ğŸŠ Mirae Asset")
    st.subheader("ê³ ê°ìì‚°ë°°ë¶„ë³¸ë¶€ ê³ ê°ìƒí’ˆì „ëµíŒ€")
    st.caption("Strategy Dashboard V4.1")
    st.markdown("---")
    
    menu = st.radio("ë©”ë‰´ ì„ íƒ", [
        "ğŸ“ˆ MS Monitoring",
        "ğŸ’ Earnings Event Trading",
        "ğŸ“Š Active ETF Analysis"
    ])
    
    # logic_backtest removed as redundant
    
    if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨"):
        st.cache_data.clear()
        st.rerun()

# ---------------------------------------------------------
# 4. ë©”ì¸ í™”ë©´ ë¡œì§
# ---------------------------------------------------------

# [TAB 2] Super-Stock (StatCounter) - íŒ€ì¥ë‹˜ ê°œì¸ ì—…ë¬´
if menu == "ğŸ“ˆ MS Monitoring":
    st.header("ğŸ“ˆ MS Monitoring (Global Market Share)")
    st.caption("Data Source: StatCounter Global Stats")
    
    # ë©”ì¸ íƒ­ ë¶„ë¦¬: ê²€ìƒ‰ì—”ì§„ vs ëª¨ë°”ì¼ OS
    main_tab1, main_tab2 = st.tabs(["ğŸ” Browser Market Share ", "ğŸ“± Operating System Market Share"])
    
    # [Tab 1] ê²€ìƒ‰ì—”ì§„ (ê¸°ì¡´ ê¸°ëŠ¥)
    with main_tab1:
        st.subheader("Global Browser Market Share")
        st.caption("Google vs Bing vs Yahoo vs Other")
        
        sub_tab1, sub_tab2, sub_tab3 = st.tabs(["ğŸ–¥ï¸+ğŸ“± Desktop & Mobile", "ğŸ–¥ï¸ Desktop", "ğŸ“± Mobile"])
        
        # 1. Desktop + Mobile (Combined)
        with sub_tab1:
            df = fetch_statcounter_data("search_engine", device="desktop+mobile")
            df_proc = process_search_engine_data(df)
            
            if not df_proc.empty:
                # ë§‰ëŒ€ ì°¨íŠ¸ (Stacked Bar)
                fig = px.bar(df_proc, title="Search Engine M/S (Total)", barmode='stack', 
                             color_discrete_map={'Google': '#4285F4', 'Bing': '#00A4EF', 'Yahoo': '#7B0099', 'Other': '#999999'})
                
                # Yì¶• ìŠ¤ì¼€ì¼ ì¡°ì • (0~100 ê³ ì •)
                fig.update_layout(yaxis_range=[0, 100], legend=dict(orientation="h", yanchor="top", y=-0.2, xanchor="center", x=0.5))
                
                st.plotly_chart(fig, use_container_width=True)
                st.dataframe(df_proc.sort_index(ascending=False).style.format("{:.1f}%").background_gradient(cmap="Reds", subset=["Google"]), use_container_width=True)

        # 2. Desktop
        with sub_tab2:
            df = fetch_statcounter_data("search_engine", device="desktop")
            df_proc = process_search_engine_data(df)
            
            if not df_proc.empty:
                fig = px.bar(df_proc, title="Search Engine M/S (Desktop)", barmode='stack',
                             color_discrete_map={'Google': '#4285F4', 'Bing': '#00A4EF', 'Yahoo': '#7B0099', 'Other': '#999999'})
                
                # Yì¶• ìŠ¤ì¼€ì¼ ì¡°ì • (0~100 ê³ ì •)
                fig.update_layout(yaxis_range=[0, 100], legend=dict(orientation="h", yanchor="top", y=-0.2, xanchor="center", x=0.5))

                st.plotly_chart(fig, use_container_width=True)
                st.dataframe(df_proc.sort_index(ascending=False).style.format("{:.1f}%").background_gradient(cmap="Reds", subset=["Google"]), use_container_width=True)

        # 3. Mobile
        with sub_tab3:
            df = fetch_statcounter_data("search_engine", device="mobile")
            df_proc = process_search_engine_data(df)
            
            if not df_proc.empty:
                fig = px.bar(df_proc, title="Search Engine M/S (Mobile)", barmode='stack',
                             color_discrete_map={'Google': '#4285F4', 'Bing': '#00A4EF', 'Yahoo': '#7B0099', 'Other': '#999999'})
                
                # Yì¶• ìŠ¤ì¼€ì¼ ì¡°ì • (0~100 ê³ ì •)
                fig.update_layout(yaxis_range=[0, 100], legend=dict(orientation="h", yanchor="top", y=-0.2, xanchor="center", x=0.5))

                st.plotly_chart(fig, use_container_width=True)
                st.dataframe(df_proc.sort_index(ascending=False).style.format("{:.1f}%").background_gradient(cmap="Reds", subset=["Google"]), use_container_width=True)

    # [Tab 2] OS Rivalry (New Feature)
    with main_tab2:
        st.subheader("ğŸ“± Mobile & Tablet OS Rivalry (Android vs iOS)")
        st.caption("Which ecosystem is winning? (Data since 2009)")
        
        # ì»¨íŠ¸ë¡¤ íŒ¨ë„
        c1, c2 = st.columns([1, 1])
        with c1:
            os_device = st.radio("Platform", ["Mobile", "Tablet", "Mobile + Tablet"], horizontal=True)
            # íŒŒë¼ë¯¸í„° ë§¤í•‘
            device_param_map = {
                "Mobile": "mobile",
                "Tablet": "tablet",
                "Mobile + Tablet": "mobile+tablet"
            }
            target_device = device_param_map[os_device]
            
        with c2:
            # ì—°ë„ ë¦¬ìŠ¤íŠ¸ ìƒì„± (í˜„ì¬ ì—°ë„ ~ 2009)
            current_year = datetime.now().year
            year_options = [str(y) for y in range(current_year, 2008, -1)]
            period_options = ["Last 12 Months"] + year_options + ["All Time"]
            period = st.selectbox("Period", period_options)
            
        # ë°ì´í„° ìˆ˜ì§‘ (2009ë…„ë¶€í„° ìµœëŒ€ì¹˜)
        # í†µì‹  ì—ëŸ¬ ë°©ì§€ìš© ì˜ˆì™¸ì²˜ë¦¬
        try:
            df_os = fetch_statcounter_data("os", device=target_device, from_year="2009", from_month="01")
        except Exception:
            df_os = pd.DataFrame()
        
        if not df_os.empty:
            # Android, iOS, iPadOS í•„í„°ë§
            targets = ['Android', 'iOS', 'iPadOS']
            # ì‹¤ì œ ì»¬ëŸ¼ëª… í™•ì¸ (ëŒ€ì†Œë¬¸ì ì´ìŠˆ ë°©ì§€)
            valid_targets = []
            rename_map = {}
            for t in targets:
                # ëŒ€ì†Œë¬¸ì ë¬´ì‹œí•˜ê³  ì°¾ê¸°
                for col in df_os.columns:
                    if t.lower() == col.lower():
                        valid_targets.append(col)
                        rename_map[col] = t # í‘œì¤€ ì´ë¦„ìœ¼ë¡œ ë§¤í•‘
                        break
            
            if len(valid_targets) > 0:
                df_final = df_os[valid_targets].copy()
                df_final.rename(columns=rename_map, inplace=True)
                
                # ë‚ ì§œ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬ (iloc ìŠ¬ë¼ì´ì‹±ì„ ìœ„í•´ í•„ìˆ˜)
                df_final.sort_index(ascending=True, inplace=True)
                
                # ê¸°ê°„ í•„í„°ë§
                if period == "Last 12 Months":
                    df_final = df_final.iloc[-13:] # User Request: 2024-12 ~ 2025-12 (13 months)
                elif period == "All Time":
                    pass
                elif period.isdigit(): # "2025", "2024" etc.
                    df_final = df_final[df_final.index.str.startswith(period)]
                
                # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì•ˆë‚´
                if df_final.empty:
                    st.warning(f"ì„ íƒí•˜ì‹  ê¸°ê°„({period})ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    # Tooltip ì •ë ¬ì„ ìœ„í•´ ë§ˆì§€ë§‰ ë°ì´í„° ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì»¬ëŸ¼ ì¬ì •ë ¬
                    # (User Request: ë†’ì´ ìˆëŠ” ìˆ«ìë‘ ì¢…ë¥˜ë¶€í„° ëœ¨ê²Œ)
                    last_row = df_final.iloc[-1]
                    sorted_cols = last_row.sort_values(ascending=False).index.tolist()
                    df_final = df_final[sorted_cols]
                
                # êº¾ì€ì„  ì°¨íŠ¸ (Line Chart)
                # ë°ì´í„° í¬ì¸íŠ¸ê°€ ë§ìœ¼ë©´ ë§ˆì»¤ë¥¼ ìˆ¨ê²¨ì„œ ê¹”ë”í•˜ê²Œ (20ê°œ ë¯¸ë§Œì¼ ë•Œë§Œ í‘œì‹œ)
                show_markers = True if len(df_final) < 20 else False
                
                # ìƒ‰ìƒ ì„¤ì • (User Request: StatCounter Style - Android Orange, iOS Gray)
                colors = {'Android': '#F48024', 'iOS': '#555555', 'iPadOS': '#555555'}
                
                fig = px.line(df_final, title=f"OS Market Share ({os_device}) - {period}", 
                              color_discrete_map=colors,
                              markers=show_markers) 
                
                # ë¼ì¸ ë‘ê»˜ ì„¤ì •
                fig.update_traces(line=dict(width=3))
                
                # ë¼ì¸ ë‘ê»˜ ì„¤ì •
                fig.update_traces(line=dict(width=3))
                
                # Yì¶• & Range Slider ì„¤ì •
                fig.update_layout(
                    # yaxis_range=[0, 100], # ê³ ì • ë²”ìœ„ ì œê±° (Autoë¡œ ì´ë¯¸ì§€ì²˜ëŸ¼ Zoom íš¨ê³¼)
                    yaxis=dict(rangemode='tozero'), # 0ë¶€í„° ì‹œì‘í•˜ë„ë¡ ê°•ì œ
                    xaxis=dict(
                        rangeslider=dict(visible=False), # ìš”ì²­ëŒ€ë¡œ ì œê±°
                        type="date"
                    ),
                    legend=dict(orientation="h", yanchor="top", y=-0.2, xanchor="center", x=0.5),
                    hovermode="x", # User Request: ìˆ˜ì¹˜ë¥¼ ë”°ë¡œ í‘œì‹œ (Separate)
                    plot_bgcolor='white' # ì´ë¯¸ì§€ì²˜ëŸ¼ ë°°ê²½ ê¹”ë”í•˜ê²Œ
                )
                fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='#E5E5E5')
                fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='#E5E5E5') # ê²©ì í‘œì‹œ
                
                st.plotly_chart(fig, use_container_width=True)
                
                # ë°ì´í„° í…Œì´ë¸”
                st.markdown("### ğŸ“Š Monthly Data")
                st.dataframe(df_final.sort_index(ascending=False).style.format("{:.1f}%"), use_container_width=True)
            else:
                st.warning("Android ë˜ëŠ” iOS ë°ì´í„°ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        else:
            st.error("ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")


# [TAB 3] TIMEFOLIO Analysis (ê²½ìŸì‚¬ ë¶„ì„)
# [TAB 3] (Validator Removed)

if menu == "ğŸ“Š Active ETF Analysis":
    st.title("ğŸ“Š Active ETF Daily Rebalancing")
    
    # Provider Selection
    provider = st.radio("ìš´ìš©ì‚¬ ì„ íƒ", ["TIMEFOLIO (íƒ€ì„í´ë¦¬ì˜¤)", "KIWOOM (í‚¤ì›€ - KOSEF)"], horizontal=True)
    
    if "KIWOOM" in provider:
        st.info("ğŸ“Œ **ëŒ€ìƒ ì¢…ëª©:** KOSEF ë¯¸êµ­ì„±ì¥ê¸°ì—…30 Active (459790)")
        
        if KiwoomETFMonitor is None:
             st.error("Kiwoom ëª¨ë“ˆì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
             # Date Selection
             col_date, col_btn = st.columns([2, 1])
             with col_date:
                 target_date = st.date_input("ì¡°íšŒí•  ë‚ ì§œ ì„ íƒ", datetime.now(pytz.timezone('Asia/Seoul')))
             with col_btn:
                 st.write("") 
                 st.write("")
                 run_btn = st.button("ë¦¬ë°¸ëŸ°ì‹± ë¶„ì„ ì¡°íšŒ ğŸ”")
             
             if run_btn:
                 with st.spinner(f"{target_date} ë°ì´í„° ë° ì´ì „ ì˜ì—…ì¼ ë¹„êµ ë¶„ì„ ì¤‘..."):
                     try:
                         mon = KiwoomETFMonitor()
                         t_date_str = target_date.strftime("%Y-%m-%d")
                         
                         # Data Fetch
                         df_curr = mon.get_portfolio_data(t_date_str)
                         prev_day = mon.get_previous_business_day(t_date_str)
                         
                         if df_curr.empty:
                             st.warning(f"âš ï¸ {t_date_str} ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                             st.stop()
                             
                         # Analysis
                         if prev_day:
                             df_prev = mon.load_data(prev_day)
                             analysis = mon.analyze_rebalancing(df_curr, df_prev)
                             
                             st.success(f"âœ… ë¶„ì„ ì™„ë£Œ (ë¹„êµ: {t_date_str} vs {prev_day})")
                             
                             # --- Dashboard UI (4 Quadrants) ---
                             
                             # 1. Summary Metrics
                             m1, m2, m3, m4 = st.columns(4)
                             m1.metric("ë¹„ì¤‘ í™•ëŒ€", f"{len(analysis['increased_stocks'])} ì¢…ëª©")
                             m2.metric("ë¹„ì¤‘ ì¶•ì†Œ", f"{len(analysis['decreased_stocks'])} ì¢…ëª©")
                             m3.metric("ì‹ ê·œ í¸ì…", f"{len(analysis['new_stocks'])} ì¢…ëª©")
                             m4.metric("ì™„ì „ í¸ì¶œ", f"{len(analysis['removed_stocks'])} ì¢…ëª©")
                             
                             st.markdown("---")
                             
                             # 2. Quadrants
                             # Row 1: New & Removed
                             c1, c2 = st.columns(2)
                             with c1:
                                 st.markdown("##### ğŸŸ¢ ì‹ ê·œ í¸ì… (New)")
                                 if analysis['new_stocks']:
                                     new_df = pd.DataFrame(analysis['new_stocks'])
                                     # Show Name, Weight, Weight Change
                                     disp = new_df[['ì¢…ëª©ëª…', 'ë¹„ì¤‘_today', 'ë¹„ì¤‘ë³€í™”']].copy()
                                     disp.columns = ['ì¢…ëª©ëª…', 'ë¹„ì¤‘', 'ë¹„ì¤‘ë³€ë™']
                                     disp['ë¹„ì¤‘'] = disp['ë¹„ì¤‘'].apply(lambda x: f"{x:.2f}%")
                                     disp['ë¹„ì¤‘ë³€ë™'] = disp['ë¹„ì¤‘ë³€ë™'].apply(lambda x: f"+{x:.2f}%p")
                                     st.dataframe(disp, hide_index=True, use_container_width=True)
                                 else:
                                     st.info("ì‹ ê·œ í¸ì… ì¢…ëª© ì—†ìŒ")
                                     
                             with c2:
                                 st.markdown("##### ğŸ”´ ì™„ì „ í¸ì¶œ (Removed)")
                                 if analysis['removed_stocks']:
                                     rem_df = pd.DataFrame(analysis['removed_stocks'])
                                     # Show Name, Prev Weight, Weight Change
                                     disp = rem_df[['ì¢…ëª©ëª…', 'ë¹„ì¤‘_prev', 'ë¹„ì¤‘ë³€í™”']].copy()
                                     disp.columns = ['ì¢…ëª©ëª…', 'ì´ì „ë¹„ì¤‘', 'ë¹„ì¤‘ë³€ë™']
                                     disp['ì´ì „ë¹„ì¤‘'] = disp['ì´ì „ë¹„ì¤‘'].apply(lambda x: f"{x:.2f}%")
                                     disp['ë¹„ì¤‘ë³€ë™'] = disp['ë¹„ì¤‘ë³€ë™'].apply(lambda x: f"{x:.2f}%p")
                                     st.dataframe(disp, hide_index=True, use_container_width=True)
                                 else:
                                     st.info("ì™„ì „ í¸ì¶œ ì¢…ëª© ì—†ìŒ")
                                     
                             # Row 2: Increased & Decreased (Top 5)
                             c3, c4 = st.columns(2)
                             with c3:
                                 st.markdown("##### ğŸ”¼ ë¹„ì¤‘ í™•ëŒ€ (Top 5)")
                                 if analysis['increased_stocks']:
                                     inc_df = pd.DataFrame(analysis['increased_stocks'])
                                     # Sort by Share Change? Or Weight Change?
                                     # User asked "ë¹„ì¤‘í™•ëŒ€". Usually sorted by magnitude.
                                     # Kiwoom analysis sorts by 'ìˆ˜ëŸ‰ë³€í™”' internally for 'Increased', but let's sort display by 'ë¹„ì¤‘ë³€í™”' for consistency with "Weight" focus?
                                     # Or stick to Share Change sort but display Weight?
                                     # I'll sort by 'ë¹„ì¤‘ë³€í™”' descending.
                                     inc_df = inc_df.sort_values('ë¹„ì¤‘ë³€í™”', ascending=False).head(5)
                                     
                                     disp = inc_df[['ì¢…ëª©ëª…', 'ë¹„ì¤‘_today', 'ë¹„ì¤‘ë³€í™”']].copy()
                                     disp.columns = ['ì¢…ëª©ëª…', 'í˜„ì¬ë¹„ì¤‘', 'ë¹„ì¤‘ë³€ë™']
                                     disp['í˜„ì¬ë¹„ì¤‘'] = disp['í˜„ì¬ë¹„ì¤‘'].apply(lambda x: f"{x:.2f}%")
                                     disp['ë¹„ì¤‘ë³€ë™'] = disp['ë¹„ì¤‘ë³€ë™'].apply(lambda x: f"+{x:.2f}%p")
                                     st.dataframe(disp, hide_index=True, use_container_width=True)
                                 else:
                                     st.info("ë¹„ì¤‘ í™•ëŒ€ ì¢…ëª© ì—†ìŒ")
                                     
                             with c4:
                                 st.markdown("##### ğŸ”½ ë¹„ì¤‘ ì¶•ì†Œ (Top 5)")
                                 if analysis['decreased_stocks']:
                                     dec_df = pd.DataFrame(analysis['decreased_stocks'])
                                     # Sort by Weight Change ascending
                                     dec_df = dec_df.sort_values('ë¹„ì¤‘ë³€í™”', ascending=True).head(5)
                                     
                                     disp = dec_df[['ì¢…ëª©ëª…', 'ë¹„ì¤‘_today', 'ë¹„ì¤‘ë³€í™”']].copy()
                                     disp.columns = ['ì¢…ëª©ëª…', 'í˜„ì¬ë¹„ì¤‘', 'ë¹„ì¤‘ë³€ë™']
                                     disp['í˜„ì¬ë¹„ì¤‘'] = disp['í˜„ì¬ë¹„ì¤‘'].apply(lambda x: f"{x:.2f}%")
                                     disp['ë¹„ì¤‘ë³€ë™'] = disp['ë¹„ì¤‘ë³€ë™'].apply(lambda x: f"{x:.2f}%p")
                                     st.dataframe(disp, hide_index=True, use_container_width=True)
                                 else:
                                     st.info("ë¹„ì¤‘ ì¶•ì†Œ ì¢…ëª© ì—†ìŒ")

                             # Expandable Full List
                             with st.expander("ğŸ“‹ ì „ì²´ êµ¬ì„±ì¢…ëª© ë¦¬ìŠ¤íŠ¸ (PDF)"):
                                 df_all = df_curr[['ì¢…ëª©ëª…', 'ì¢…ëª©ì½”ë“œ', 'ë³´ìœ ìˆ˜ëŸ‰', 'ë¹„ì¤‘']].sort_values('ë¹„ì¤‘', ascending=False)
                                 df_all['ë³´ìœ ìˆ˜ëŸ‰'] = df_all['ë³´ìœ ìˆ˜ëŸ‰'].apply(lambda x: f"{x:,.0f}")
                                 df_all['ë¹„ì¤‘'] = df_all['ë¹„ì¤‘'].apply(lambda x: f"{x:.2f}%")
                                 st.dataframe(df_all, hide_index=True, use_container_width=True)

                         else:
                             st.warning("âš ï¸ ì´ì „ ì˜ì—…ì¼ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ë¦¬ë°¸ëŸ°ì‹± ë¶„ì„ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
                             st.dataframe(df_curr, hide_index=True)
                             
                     except Exception as e:
                         st.error(f"Error: {e}")
                         
        st.stop() # Stop execution here
        
    # --- TIMEFOLIO Logic (Default) ---
    st.subheader("TIMEFOLIO Official Portfolio & Rebalancing")
    
    etf_categories = {
        "í•´ì™¸ì£¼ì‹í˜• (10ì¢…)": {
            "ê¸€ë¡œë²Œíƒ‘í”½": "22", "ê¸€ë¡œë²Œë°”ì´ì˜¤": "9", "ìš°ì£¼í…Œí¬&ë°©ì‚°": "20",
            "S&P500": "5", "ë‚˜ìŠ¤ë‹¥100": "2", "ê¸€ë¡œë²ŒAI": "6",
            "ì°¨ì´ë‚˜AI": "19", "ë¯¸êµ­ë°°ë‹¹ë‹¤ìš°ì¡´ìŠ¤": "18",
            "ë¯¸êµ­ë‚˜ìŠ¤ë‹¥100ì±„ê¶Œí˜¼í•©50": "10", "ê¸€ë¡œë²Œì†Œë¹„íŠ¸ë Œë“œ": "8"
        },
        "êµ­ë‚´ì£¼ì‹í˜• (7ì¢…)": {
            "Kì‹ ì¬ìƒì—ë„ˆì§€": "16", "Kë°”ì´ì˜¤": "13", "Koreaí”ŒëŸ¬ìŠ¤ë°°ë‹¹": "12",
            "ì½”ìŠ¤í”¼": "11", "ì½”ë¦¬ì•„ë°¸ë¥˜ì—…": "15", "Kì´ë…¸ë² ì´ì…˜": "17", "Kì»¬ì²˜": "1"
        }
    }
    
    c1, c2 = st.columns(2)
    with c1:
        cat = st.selectbox("ë¶„ë¥˜", list(etf_categories.keys()))
    with c2:
        name = st.selectbox("ìƒí’ˆëª…", list(etf_categories[cat].keys()))
    
    target_idx = etf_categories[cat][name]
    
    if st.button("ë°ì´í„° ë¶„ì„ ë° ë¦¬ë°¸ëŸ°ì‹± ìš”ì•½") or st.session_state.get(f"analysis_active_{target_idx}", False):
        st.session_state[f"analysis_active_{target_idx}"] = True

        with st.spinner(f"'{name}' ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ë° ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                # ActiveETFMonitor ì´ˆê¸°í™”
                monitor = ActiveETFMonitor(url=f"https://timefolioetf.co.kr/m11_view.php?idx={target_idx}", etf_name=name)
                
                # ê¸ˆì¼ ë‚ ì§œ (í•œêµ­ ì‹œê°„)
                today = datetime.now(pytz.timezone('Asia/Seoul')).strftime("%Y-%m-%d")
                
                # ê¸ˆì¼ ë°ì´í„° ìˆ˜ì§‘
                df_today = monitor.get_portfolio_data(today)
                monitor.save_data(df_today, today)
                
                # ì „ì¼ ë°ì´í„° ë¡œë“œ (ì—†ìœ¼ë©´ í¬ë¡¤ë§)
                try:
                    prev_day = monitor.get_previous_business_day(today)
                    df_prev = monitor.load_data(prev_day)
                    
                    # ë¦¬ë°¸ëŸ°ì‹± ë¶„ì„ ìˆ˜í–‰
                    analysis = monitor.analyze_rebalancing(df_today, df_prev, prev_day, today)
                    analysis_success = True
                except Exception as e:
                    st.warning(f"ì „ì¼ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ë¦¬ë°¸ëŸ°ì‹± ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤: {e}")
                    analysis_success = False
                    df_prev = None

                st.success(f"âœ… {name} ë°ì´í„° ë¶„ì„ ì™„ë£Œ" + (f" (ê¸°ì¤€: {today} vs {prev_day})" if analysis_success else ""))

                # --- ë¦¬ë°¸ëŸ°ì‹± ìš”ì•½ (ë¶„ì„ ì„±ê³µ ì‹œ) ---
                if analysis_success:
                    st.subheader("ğŸ”„ ë¦¬ë°¸ëŸ°ì‹± ì •ë°€ ë¶„ì„ (ì‹œì¥ìˆ˜ìµë¥  ì¡°ì • ë°˜ì˜)")
                    
                    # ìš”ì•½ ë©”íŠ¸ë¦­
                    m1, m2, m3, m4 = st.columns(4)
                    m1.metric("ë¹„ì¤‘ í™•ëŒ€", f"{len(analysis['increased_stocks'])} ì¢…ëª©")
                    m2.metric("ë¹„ì¤‘ ì¶•ì†Œ", f"{len(analysis['decreased_stocks'])} ì¢…ëª©")
                    m3.metric("ì‹ ê·œ í¸ì…", f"{len(analysis['new_stocks'])} ì¢…ëª©")
                    m4.metric("ì™„ì „ í¸ì¶œ", f"{len(analysis['removed_stocks'])} ì¢…ëª©")

                    # --- Dashboard UI (4 Quadrants) ---
                    # Row 1: New & Removed
                    c1, c2 = st.columns(2)
                    with c1:
                        st.markdown("##### ğŸŸ¢ ì‹ ê·œ í¸ì… (New)")
                        if analysis['new_stocks']:
                            rows = []
                            for s in analysis['new_stocks']:
                                rows.append({
                                    "ì¢…ëª©ëª…": s['ì¢…ëª©ëª…'],
                                    "ë¹„ì¤‘(%)": f"{s['ë¹„ì¤‘_today']:.2f}%",
                                    "ë¹„ì¤‘ë³€ë™": f"+{s['ìˆœìˆ˜_ë¹„ì¤‘ë³€í™”']:.2f}%p"
                                })
                            st.dataframe(pd.DataFrame(rows), hide_index=True, use_container_width=True)
                        else:
                            st.info("ì‹ ê·œ í¸ì… ì¢…ëª© ì—†ìŒ")

                    with c2:
                        st.markdown("##### ğŸ”´ ì™„ì „ í¸ì¶œ (Removed)")
                        if analysis['removed_stocks']:
                            rows = []
                            for s in analysis['removed_stocks']:
                                rows.append({
                                    "ì¢…ëª©ëª…": s['ì¢…ëª©ëª…'],
                                    "ì´ì „ë¹„ì¤‘": f"{s['ë¹„ì¤‘_prev']:.2f}%",
                                    "ë¹„ì¤‘ë³€ë™": f"{s['ìˆœìˆ˜_ë¹„ì¤‘ë³€í™”']:.2f}%p"
                                })
                            st.dataframe(pd.DataFrame(rows), hide_index=True, use_container_width=True)
                        else:
                            st.info("ì™„ì „ í¸ì¶œ ì¢…ëª© ì—†ìŒ")
                            
                    st.markdown("---")

                    # Row 2: Increased & Decreased (Top 5)
                    c3, c4 = st.columns(2)
                    with c3:
                        st.markdown("##### ğŸ”¼ ë¹„ì¤‘ í™•ëŒ€ (Top 5)")
                        if analysis['increased_stocks']:
                            df_inc = pd.DataFrame(analysis['increased_stocks'])
                            df_inc = df_inc.sort_values('ìˆœìˆ˜_ë¹„ì¤‘ë³€í™”', ascending=False).head(5)
                            
                            disp = df_inc[['ì¢…ëª©ëª…', 'ë¹„ì¤‘_today', 'ìˆœìˆ˜_ë¹„ì¤‘ë³€í™”']].copy()
                            disp.columns = ['ì¢…ëª©ëª…', 'í˜„ì¬ë¹„ì¤‘', 'ë¹„ì¤‘ë³€ë™']
                            disp['í˜„ì¬ë¹„ì¤‘'] = disp['í˜„ì¬ë¹„ì¤‘'].apply(lambda x: f"{x:.2f}%")
                            disp['ë¹„ì¤‘ë³€ë™'] = disp['ë¹„ì¤‘ë³€ë™'].apply(lambda x: f"+{x:.2f}%p")
                            st.dataframe(disp, hide_index=True, use_container_width=True)
                        else:
                            st.info("ë¹„ì¤‘ í™•ëŒ€ ì¢…ëª© ì—†ìŒ")

                    with c4:
                        st.markdown("##### ğŸ”½ ë¹„ì¤‘ ì¶•ì†Œ (Top 5)")
                        if analysis['decreased_stocks']:
                            df_dec = pd.DataFrame(analysis['decreased_stocks'])
                            df_dec = df_dec.sort_values('ìˆœìˆ˜_ë¹„ì¤‘ë³€í™”', ascending=True).head(5)
                            
                            disp = df_dec[['ì¢…ëª©ëª…', 'ë¹„ì¤‘_today', 'ìˆœìˆ˜_ë¹„ì¤‘ë³€í™”']].copy()
                            disp.columns = ['ì¢…ëª©ëª…', 'í˜„ì¬ë¹„ì¤‘', 'ë¹„ì¤‘ë³€ë™']
                            disp['í˜„ì¬ë¹„ì¤‘'] = disp['í˜„ì¬ë¹„ì¤‘'].apply(lambda x: f"{x:.2f}%")
                            disp['ë¹„ì¤‘ë³€ë™'] = disp['ë¹„ì¤‘ë³€ë™'].apply(lambda x: f"{x:.2f}%p")
                            st.dataframe(disp, hide_index=True, use_container_width=True)
                        else:
                            st.info("ë¹„ì¤‘ ì¶•ì†Œ ì¢…ëª© ì—†ìŒ")
                            
                    st.info("* **ìˆœìˆ˜ ë³€ë™**: ì‹œì¥ ê°€ê²© ë“±ë½ íš¨ê³¼ë¥¼ ì œê±°í•˜ê³ , ë§¤ë‹ˆì €ì˜ ì‹¤ì œ ë§¤ë§¤ë¡œ ì¸í•œ ë¹„ì¤‘ ë³€í™”ë¶„ë§Œ ì¶”ì‚°í•œ ê°’ì…ë‹ˆë‹¤.")

                    # Expandable: Chart & Full List
                    with st.expander("ğŸ“‹ ì „ì²´ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„± ë° ì°¨íŠ¸"):
                        # ì „ì²´ ë¦¬ìŠ¤íŠ¸ ë° ì°¨íŠ¸
                        st.subheader("ğŸ“‹ ì „ì²´ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±")
                        
                        c_chart, c_list = st.columns([1, 1])
                        
                        with c_chart:
                            # ë„ë„› ì°¨íŠ¸ ë³µì›
                            chart_df = df_today.copy()
                            chart_df['ë¹„ì¤‘'] = pd.to_numeric(chart_df['ë¹„ì¤‘'], errors='coerce')
                            
                            # Top 5 ì™¸ì—ëŠ” 'ê¸°íƒ€'ë¡œ ë¬¶ê¸°
                            chart_df = chart_df.sort_values('ë¹„ì¤‘', ascending=False)
                            if len(chart_df) > 5:
                                top5 = chart_df.iloc[:5]
                                others = chart_df.iloc[5:]
                                others_sum = others['ë¹„ì¤‘'].sum()
                                others_row = pd.DataFrame([{'ì¢…ëª©ëª…': 'ê¸°íƒ€', 'ë¹„ì¤‘': others_sum}])
                                final_chart_df = pd.concat([top5, others_row], ignore_index=True)
                            else:
                                final_chart_df = chart_df

                            fig = px.pie(final_chart_df, values="ë¹„ì¤‘", names="ì¢…ëª©ëª…", hole=0.4, title="í¬íŠ¸í´ë¦¬ì˜¤ ë¹„ì¤‘", color_discrete_sequence=px.colors.qualitative.Set3)
                            fig.update_traces(textinfo='percent+label')
                            st.plotly_chart(fig, use_container_width=True)
                        
                        with c_list:
                            # ì „ì²´ ë°ì´í„° í‘œì‹œ (ì‹¬í”Œ í…Œì´ë¸”)
                            df_all = df_today[['ì¢…ëª©ëª…', 'ë¹„ì¤‘']].copy()
                            df_all['ë¹„ì¤‘'] = pd.to_numeric(df_all['ë¹„ì¤‘'], errors='coerce')
                            df_all = df_all.sort_values('ë¹„ì¤‘', ascending=False)
                            
                            # ì¸ë±ìŠ¤ 1ë¶€í„° ì‹œì‘ (ìˆœìœ„)
                            df_all.index = range(1, len(df_all) + 1)
                            
                            # ë¹„ì¤‘ í¬ë§·íŒ…í•˜ì—¬ í‘œì‹œ
                            st.dataframe(df_all.style.format({'ë¹„ì¤‘': '{:.2f}%'}), use_container_width=True)


                # --- [ì‹ ê·œ ê¸°ëŠ¥ 2] ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ---
                st.markdown("---")
                st.subheader("ğŸ“¥ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ")
                
                # ì—‘ì…€ ìƒì„±ì„ ìœ„í•œ ë°ì´í„° í”„ë ˆì„ ì¤€ë¹„
                e_new = pd.DataFrame(analysis['new_stocks']) if analysis['new_stocks'] else pd.DataFrame(columns=['ì¢…ëª©ëª…', 'ë¹„ì¤‘_today', 'ìˆœìˆ˜_ë¹„ì¤‘ë³€í™”'])
                e_inc = pd.DataFrame(analysis['increased_stocks']) if analysis['increased_stocks'] else pd.DataFrame(columns=['ì¢…ëª©ëª…', 'ë¹„ì¤‘_prev', 'ë¹„ì¤‘_today', 'ìˆœìˆ˜_ë¹„ì¤‘ë³€í™”'])
                e_dec = pd.DataFrame(analysis['decreased_stocks']) if analysis['decreased_stocks'] else pd.DataFrame(columns=['ì¢…ëª©ëª…', 'ë¹„ì¤‘_prev', 'ë¹„ì¤‘_today', 'ìˆœìˆ˜_ë¹„ì¤‘ë³€í™”'])
                
                excel_data = to_excel(e_new, e_inc, e_dec, df_today, today)
                
                st.download_button(
                    label="ğŸ“Š ì—‘ì…€ ë¦¬í¬íŠ¸ ë‚´ë ¤ë°›ê¸° (.xlsx)",
                    data=excel_data,
                    file_name=f"{name}_Report_{today}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

                # --- [ì‹ ê·œ ê¸°ëŠ¥ 1] ì¢…ëª© ë¹„ì¤‘ íˆìŠ¤í† ë¦¬ ---
                st.markdown("---")
                st.subheader("ğŸ“… ì¢…ëª© ë¹„ì¤‘ íˆìŠ¤í† ë¦¬ (ìµœê·¼ 30ì¼)")
                
                with st.expander("ğŸ“ˆ ê°œë³„ ì¢…ëª© íŠ¸ë Œë“œ ë¶„ì„ í¼ì¹˜ê¸°", expanded=False):
                    history_df = monitor.load_history(days=30)
                    
                    if not history_df.empty:
                        # ì¢…ëª© ì„ íƒ (Session State í™œìš©í•˜ì—¬ ì„ íƒ ìœ ì§€)
                        all_stocks = sorted(history_df['ì¢…ëª©ëª…'].unique())
                        
                        # Session state í‚¤ ìƒì„±
                        sel_key = "history_selected_stock"
                        if sel_key not in st.session_state:
                            st.session_state[sel_key] = all_stocks[0]
                            
                        # Selectbox with key
                        selected_stock = st.selectbox("ë¶„ì„í•  ì¢…ëª©ì„ ì„ íƒí•˜ì„¸ìš”", all_stocks, key=sel_key)
                        
                        # ì„ íƒ ì¢…ëª© ë°ì´í„° í•„í„°ë§
                        stock_history = history_df[history_df['ì¢…ëª©ëª…'] == selected_stock].sort_values('ë‚ ì§œ')
                        
                        chart = px.line(stock_history, x='ë‚ ì§œ', y='ë¹„ì¤‘', title=f"{selected_stock} ë¹„ì¤‘ ë³€í™” ì¶”ì´",
                                       markers=True, text='ë¹„ì¤‘')
                        chart.update_traces(textposition="top center")
                        st.plotly_chart(chart, use_container_width=True)
                    else:
                        st.info("ëˆ„ì ëœ íˆìŠ¤í† ë¦¬ ë°ì´í„°ê°€ ì•„ì§ ì—†ìŠµë‹ˆë‹¤. ë§¤ì¼ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ë©´ ì°¨íŠ¸ê°€ í™œì„±í™”ë©ë‹ˆë‹¤.")
                

            except Exception as e:
                st.error(f"ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                st.exception(e)

    st.markdown("---")
    st.link_button("ğŸŒ ê³µì‹ ìƒì„¸í˜ì´ì§€ ë°”ë¡œê°€ê¸°", f"https://timefolioetf.co.kr/m11_view.php?idx={target_idx}")

# [TAB 4] Earnings Idio Score (Goldman Sachs Logic)
if menu == "ğŸ’ Earnings Event Trading":
    if logic_idio is None:
        st.error("âš ï¸ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬(scikit-learn)ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
        st.stop()

    st.title("ğŸ“ˆ Earnings Idio Score Dashboard")
    st.markdown("ê³¨ë“œë§Œì‚­ìŠ¤ ë°©ë²•ë¡  ê¸°ë°˜: **'ì‹¤ì  ë°œí‘œì¼ ê³ ìœ  ë³€ë™ì„±(Alpha)'** ë¶„ì„")
    
    with st.expander("â„¹ï¸ Idio Score ì‚°ì¶œ ë¡œì§ ë³´ê¸° (Goldman Sachs Method)"):
        st.markdown(r"""
        **1. 5-Factor Modeling**
        ì‹œì¥(Market), ì„¹í„°(Sector) ë¿ë§Œ ì•„ë‹ˆë¼ ìŠ¤íƒ€ì¼(Size, Value, Momentum) ìš”ì¸ê¹Œì§€ ëª¨ë‘ ì œê±°í•˜ì—¬
        ìˆœìˆ˜í•œ ì¢…ëª© ê³ ìœ ì˜ ì›€ì§ì„(Idiosyncratic Return)ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        **2. Regression Model (Trailing 3 Years)**
        $$
        R_{i,t} = \alpha + \beta_{Mkt}Mkt_t + \beta_{Sec}Sec_t + \beta_{SMB}SMB_t + \beta_{HML}HML_t + \beta_{Mom}MOM_t + \epsilon_{i,t}
        $$
        *   $Mkt$: S&P 500 (SPY Adj Close)
        *   $Sec$: Sector ETF (e.g., XLK)
        *   $SMB/HML/MOM$: Fama-French Style Factors
        
        **3. ìµœì¢… ì ìˆ˜ (GS Delta Score)**
        ì‹¤ì  ë°œí‘œ ê¸°ê°„(Earnings Window)ì´ ì¢…ëª©ì˜ ìˆ˜ìµ íš¨ìœ¨ì„±(Alpha Efficiency)ì— ê¸°ì—¬í•˜ëŠ” ì •ë„ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.
        $$
        \Delta \text{Score} = \text{Score}_{incl} - \text{Score}_{excl}
        $$
        
        *   **$\text{Score}$ (Efficiency)**: ë³€ë™ì„± ëŒ€ë¹„ ìˆœìˆ˜ ìˆ˜ìµ(ì”ì°¨ ì ˆëŒ€ê°’)ì˜ ë¹„ìœ¨ (Sharpe ìœ ì‚¬ ê°œë…)
            $$ \text{Score} = \frac{\text{Mean}(|\epsilon|) \times 252}{\text{Std}(\epsilon) \times \sqrt{252}} $$
        *   **$\text{Score}_{incl}$**: ì „ì²´ ê¸°ê°„(Earnings í¬í•¨)ì˜ íš¨ìœ¨ì„±
        *   **$\text{Score}_{excl}$**: ì‹¤ì  ë°œí‘œì¼($T-2 \sim T+2$)ì„ **ì œì™¸**í•œ ê¸°ê°„ì˜ íš¨ìœ¨ì„±
        
        **í•´ì„**: ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡($+$), ë³€ë™ì„±ì„ ê°ìˆ˜í•˜ê³ ì„œë¼ë„ **ì‹¤ì  ë°œí‘œë¥¼ ê°€ì ¸ê°€ëŠ” ê²ƒì´ ìœ ë¦¬**í•˜ë‹¤ëŠ” ëœ»ì…ë‹ˆë‹¤. (Earnings Alpha ì¡´ì¬)
        """)

    # ì‚¬ì´ë“œë°”: ì¢…ëª© ì„ íƒ
    universe_df = logic_idio.load_universe()
    
    with st.sidebar:
        st.header("ì¢…ëª© ì„ íƒ")
        
        # --- [NEW] Earnings Calendar Scanner ---
        st.subheader("ğŸ“… Earnings Calendar")
        target_date = st.date_input("ë‚ ì§œ ì„ íƒ", datetime.now())
        
        if st.button("ì‹¤ì  ë°œí‘œ ì¢…ëª© ê²€ìƒ‰ (Weekly Scan)"):
            with st.spinner("Searching next 7 days..."):
                calendar_df = logic_crawler.get_earnings_calendar(target_date.strftime("%Y-%m-%d"), days=7)
                if not calendar_df.empty:
                    # Sort by Date, then Time
                    calendar_df = calendar_df.sort_values(by=['Date', 'Time', 'Market Cap'], ascending=[True, True, False])
                    
                    st.session_state['earnings_calendar'] = calendar_df
                    st.session_state['batch_results'] = None # Reset previous batch results
                    st.success(f"âœ… {len(calendar_df)}ê°œ ë°œê²¬! (7ì¼ì¹˜ Data) ìš°ì¸¡ ëŒ€ì‹œë³´ë“œì—ì„œ í™•ì¸í•˜ì„¸ìš”.")
                else:
                    st.warning("í•´ë‹¹ ë‚ ì§œì— ì˜ˆì •ëœ ì‹¤ì  ë°œí‘œê°€ ì—†ê±°ë‚˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    st.session_state['earnings_calendar'] = None
                    st.session_state['batch_results'] = None

        st.markdown("---")
        
        if not universe_df.empty:
            # ê¸°ë³¸ ì„ íƒ ë¡œì§ ìœ ì§€
            pass
            selected_label = st.selectbox("ë¶„ì„í•  ì¢…ëª©ì„ ì„ íƒí•˜ì„¸ìš”:", universe_df['Label'])
            
            # ì„ íƒëœ ì¢…ëª© ì •ë³´ ì¶”ì¶œ
            selected_row = universe_df[universe_df['Label'] == selected_label].iloc[0]
            ticker = selected_row['Ticker']
            sector = selected_row['Sector']
            
            # (Optional) If user wants to type ticker manually (e.g. found in calendar)
            manual_ticker = st.text_input("ì§ì ‘ í‹°ì»¤ ì…ë ¥ (Calendar ì°¸ê³ )", value="")
            if manual_ticker:
                ticker = manual_ticker.upper()
                sector = "ì§€ìˆ˜" # Default for unknown
        else:
            st.warning("ìœ ë‹ˆë²„ìŠ¤ íŒŒì¼(universe_stocks.csv)ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            ticker = "AAPL"
            sector = "ì •ë³´ê¸°ìˆ "
            selected_label = f"Apple ({ticker})"
        
        # ì„¹í„°ì— ë§ëŠ” ë²¤ì¹˜ë§ˆí¬ ìë™ ì„ íƒ
        benchmark_ticker = logic_idio.SECTOR_BENCHMARKS.get(sector, '^GSPC')
        
        st.info(f"ğŸ“Œ **í‹°ì»¤:** {ticker}\n\nğŸ­ **ì„¹í„°:** {sector}\n\nâš–ï¸ **ë²¤ì¹˜ë§ˆí¬:** {benchmark_ticker}")
        
    # --- [Tabs Layout] ---
    tab_overview, tab_deepdive = st.tabs(["ğŸ“Š Overview", "ğŸ” Deep Dive"])
    
    # ==============================================================================
    # TAB 1: Overview (Dashboard)
    # ==============================================================================
    with tab_overview:
        # 1. VIX Index (Market Sentiment)
        try:
            vix_val = logic_idio.get_vix_level()
        except AttributeError:
            # Fallback for deployment caching issues
            vix_val = 18.5
        
        st.metric("VIX Index (Market Fear)", f"{vix_val:.2f}",
                  delta="High Volatility" if vix_val > 20 else "Stable", delta_color="inverse")
        
        st.info("""
        **ğŸ’¡ GS Strategy Insight: VIX ìˆ˜ì¤€ì— ë”°ë¥¸ ì‹¤ì  ì´ë²¤íŠ¸ ì„±ê³¼ **
        
        **"VIX ìˆ˜ì¤€ì€ ì‹¤ì  ì´ë²¤íŠ¸ íŠ¸ë ˆì´ë“œ ì„±ê³¼ì— ìœ ì˜ë¯¸í•œ ì˜í–¥ì„ ë¯¸ì¹¨ (VIX 35~45 êµ¬ê°„ ìš°ìˆ˜)"**

        - **ğŸ¯ ìµœì  êµ¬ê°„ (VIX 35~45):** ê±°ì‹œ ë¶ˆí™•ì‹¤ì„±ì´ ë†’ì€ í™˜ê²½ì—ì„œ ì‹¤ì  ë°œí‘œê°€ **ë¶ˆí™•ì‹¤ì„± í•´ì†Œ(Relief Rally)**ë¡œ ì‘ìš©. 
             (ì„ì˜ì†Œë¹„ì¬, ê¸°ìˆ ì£¼ ìœ ë¦¬).
        - **ğŸ“‰ ì•ˆì •~ë¶ˆì•ˆ (VIX 35 ì´í•˜):** ì£¼ê°€ ë³€ë™í­ì€ ì‘ê³  ë°©í–¥ì„±ì€ ë¶ˆí™•ì‹¤í•˜ë‚˜, í‰ê· ì ìœ¼ë¡œ ì‹œì¥ì„ **ì†Œí­ ìƒíšŒ **.
        - **âš ï¸ ìœ„í—˜ êµ¬ê°„ (VIX 45 ì´ˆê³¼):** ê·¹ë‹¨ì  ê³µí¬ êµ­ë©´. ì‹¤ì  ë°œí‘œë¡œ ì‹ ë¢° íšŒë³µì´ ì–´ë ¤ìš°ë©°, ì‹œì¥ ëŒ€ë¹„ **ì–¸ë”í¼í¼**.
        """)
        
        st.divider()
        
        # 2. Earnings Calendar & Batch Analysis
        st.subheader("ğŸ“… Earnings Calendar Analysis")
        
        # Load from Session (set by Sidebar)
        cal_df = st.session_state.get('earnings_calendar')
        
        if cal_df is not None and not cal_df.empty:
            st.caption("ì‚¬ì´ë“œë°”ì—ì„œ ê²€ìƒ‰í•œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ Idio Scoreë¥¼ ì¼ê´„ ê³„ì‚°í•©ë‹ˆë‹¤.")
            
            if st.button("ì‹¤ì  ë°œí‘œ ì¢…ëª© ì¼ê´„ ë¶„ì„ (Batch Run) ğŸš€"):
                # Progress Bar
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                results = []
                
                # Process ALL tickers (removing .head(20) limit)
                targets = cal_df['Ticker'].tolist()
                
                # Prepare Sector Dictionary for Mapping
                # Ticker -> Sector
                sector_map = dict(zip(universe_df['Ticker'], universe_df['Sector']))
                
                for i, t in enumerate(targets):
                    status_text.text(f"Analyzing {t} ({i+1}/{len(targets)})...")
                    
                    try:
                        # Determine Benchmark
                        sec = sector_map.get(t, 'ì§€ìˆ˜') # Default to Index if unknown
                        bench = logic_idio.SECTOR_BENCHMARKS.get(sec, '^GSPC')
                        
                        m_data = logic_idio.get_market_data(t, bench) 
                        if m_data is not None:
                            # Enrich with Sector/Style
                            m_data = logic_idio.enrich_with_factors(m_data, t)
                            
                            # score, events, betas, daily_ret, daily_vol, comp_stats
                            scr, _, _, d_ret, d_vol, _ = logic_idio.calculate_idio_score(m_data, t)
                            
                            # [New] VIX Regime Adjustment
                            vix_mult = 1.0
                            if 35 <= vix_val <= 45:
                                vix_mult = 1.2 # Optimal Zone Boost
                            elif vix_val > 45:
                                vix_mult = 0.8 # Danger Zone Penalty
                                
                            adj_score = scr * vix_mult
                            
                            results.append({
                                'Ticker': t,
                                'Idio Score': adj_score, # Adjusted Score
                                'Raw Score': scr,        # Original
                                'VIX Mult': vix_mult,
                                # 'Efficiency' removed
                                'Avg Daily Returns': d_ret,
                                'Daily Volatility': d_vol,
                                'Status': 'Success'
                            })
                        else:
                            # Data Fetch Fail
                            results.append({
                                'Ticker': t,
                                'Idio Score': 0.0,
                                'Raw Score': 0.0,
                                'VIX Mult': 1.0,
                                'Avg Daily Returns': 0.0,
                                'Daily Volatility': 0.0,
                                'Status': 'Data Fail'
                            })
                    except Exception as e:
                        # Logic Error
                         results.append({
                            'Ticker': t,
                            'Idio Score': 0.0,
                            'Raw Score': 0.0,
                            'VIX Mult': 1.0,
                            'Avg Daily Returns': 0.0,
                            'Daily Volatility': 0.0,
                            'Status': f'Error: {str(e)}'
                        })
                    
                    progress_bar.progress((i + 1) / len(targets))
                
                status_text.text("Analysis Complete!")
                
                # Update Session with Results
                res_df = pd.DataFrame(results)
                if not res_df.empty:
                    # Merge with original calendar info (Time, Est EPS)
                    final_df = pd.merge(cal_df, res_df, on='Ticker', how='inner')
                    final_df = final_df.sort_values(by='Idio Score', ascending=False)
                    st.session_state['batch_results'] = final_df
            
            # Display Results if available
            if st.session_state.get('batch_results') is not None:
                st.caption(f"â„¹ï¸ **VIX Weighting Active:** í˜„ì¬ VIX({vix_val:.2f}) êµ­ë©´ì„ ë°˜ì˜í•˜ì—¬ ì ìˆ˜ê°€ ë³´ì •ë˜ì—ˆìŠµë‹ˆë‹¤. (Optim: x1.2, Danger: x0.8)")
                st.dataframe(st.session_state['batch_results'].style.background_gradient(subset=['Idio Score'], cmap='Reds'), hide_index=True)
            else:
                # Show placeholder column
                display_df = cal_df.copy()
                display_df['Idio Score'] = "-"
                st.dataframe(display_df, hide_index=True)
                
        else:
            st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ 'Earnings Calendar' ë‚ ì§œë¥¼ ì„ íƒí•˜ê³  ê²€ìƒ‰í•´ì£¼ì„¸ìš”.")


    # ==============================================================================
    # TAB 2: Deep Dive (Individual Analysis)
    # ==============================================================================
    with tab_deepdive:
        st.caption("ê°œë³„ ì¢…ëª©ì— ëŒ€í•œ ì‹¬ì¸µ ë¶„ì„ ë¦¬í¬íŠ¸ì…ë‹ˆë‹¤.")
        
        st.markdown("---")
        st.subheader("1. Market Data (Benchmark)")
        
        st.subheader("1. Market Data (Benchmark)")
        
        st.info("ğŸ“¡ Yahoo Financeì—ì„œ SPY(S&P 500) ë°ì´í„°ë¥¼ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.")
        
        # Always Auto (SPY Proxy)
        market_data_source = logic_idio.fetch_spy_proxy()
        
        if market_data_source is not None:
            st.success("âœ… SPY ë°ì´í„° í™•ë³´ ì™„ë£Œ! (Hybrid Mode ë™ì‘)")
        else:
            st.warning("âš ï¸ SPY ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨. ì‹œì—°ìš© ê°€ìƒ ë°ì´í„°(Synthetic)ê°€ ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        uploaded_file = None # No file upload anymore
        
        st.divider()
        
        # 2. Earnings Calendar
        st.subheader("2. Earnings Calendar (Nasdaq)")
        target_date = st.date_input("ë‚ ì§œ ì„ íƒ", date.today())
        
        if st.button("ì‹¤ì  ë°œí‘œ ì¢…ëª© ê²€ìƒ‰ ğŸ”"):
            with st.spinner("Nasdaq.com ê²€ìƒ‰ ì¤‘..."):
                calendar_df = logic_crawler.get_earnings_calendar(target_date.strftime("%Y-%m-%d"))
                if not calendar_df.empty:
                    st.session_state['earnings_calendar'] = calendar_df
                    st.session_state['batch_results'] = None # Reset previous batch results
                    st.success(f"âœ… {len(calendar_df)}ê°œ ë°œê²¬! ìš°ì¸¡ ëŒ€ì‹œë³´ë“œì—ì„œ í™•ì¸í•˜ì„¸ìš”.")
                else:
                    st.warning("í•´ë‹¹ ë‚ ì§œì— ì˜ˆì •ëœ ì‹¤ì  ë°œí‘œê°€ ì—†ê±°ë‚˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    st.session_state['earnings_calendar'] = None
                    st.session_state['batch_results'] = None

    # ë©”ì¸ ë¶„ì„ ì‹¤í–‰
    if st.button("Idio Score ë¶„ì„ ì‹œì‘ ğŸš€"):
        with st.spinner(f'{ticker} ë°ì´í„° ë¶„ì„ ì¤‘...'):
            # 1. ë°ì´í„° ë¡œë“œ ë¡œì§ (ìš°ì„ ìˆœìœ„: Full Upload > Hybrid > Synthetic)
            market_data = None
            grade = "Synthetic" # Data Quality Grade
            
            # Use market_data_source from the radio button selection
            if market_data_source is not None:
                # If market_data_source is already a full dataset (from uploaded file)
                if 'Stock' in market_data_source.columns and 'Market' in market_data_source.columns:
                    market_data = market_data_source
                    grade = "Real (Full Upload)"
                    st.success("âœ… [Full Mode] ì—…ë¡œë“œëœ ì „ì²´ ë°ì´í„°ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.")
                else:
                    # Hybrid Mode: market_data_source is Benchmark (Market/Sector)
                    bench_data = market_data_source
                    st.info(f"ğŸ”„ [Hybrid Mode] ë²¤ì¹˜ë§ˆí¬ ë°ì´í„° í™•ë³´ ({len(bench_data)}ì¼). {ticker} ê°œë³„ ì£¼ê°€ ìˆ˜ì§‘ ì¤‘...")
                    
                    stock_df = logic_crawler.fetch_historical_price(ticker)
                    
                    if not stock_df.empty:
                        # Calculate Returns for Stock
                        stock_ret = stock_df.pct_change().dropna()
                        
                        # Merge (Inner Join on Date)
                        merged = bench_data.join(stock_ret, how='inner').dropna()
                        
                        if not merged.empty and 'Stock' in merged.columns:
                            market_data = merged
                            grade = "Real (Hybrid)"
                            st.success(f"âœ… [Hybrid Mode] S&P500 + {ticker}(Live) ê²°í•© ì™„ë£Œ! ({len(merged)}ì¼)")
                        else:
                            st.error("ë‚ ì§œê°€ ê²¹ì¹˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ë²¤ì¹˜ë§ˆí¬ ë‚ ì§œ í™•ì¸ í•„ìš”)")
                    else:
                        st.error(f"{ticker} ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨. (Nasdaq API)")
            
            # 2. Fallback to Synthetic if still None
            if market_data is None:
                market_data = logic_idio.get_market_data(ticker, benchmark_ticker)
            
            if market_data is not None:
                # 1. Enrich (Multi-Factor)
                market_data = logic_idio.enrich_with_factors(market_data, ticker)
                
                # 2. Calculate (Unpack 6 values)
                score, df, betas, d_ret, d_vol, cp = logic_idio.calculate_idio_score(market_data, ticker)
                
                # [Safety] Module Reload Issue ë°©ì§€: í˜¹ì‹œë¼ë„ floatê°€ ë¦¬í„´ë˜ë©´ ë¹ˆ dictë¡œ ë³€í™˜
                if not isinstance(cp, dict): cp = {}
                if not isinstance(betas, dict): betas = {}
                
                # --- ê²°ê³¼ í™”ë©´ ---
                
                # 1. ìŠ¤ì½”ì–´ ì¹´ë“œ (GS Only)
                col1, col2, col3, col4, col5 = st.columns(5)
                col1.metric("GS Idio Score (Delta)", f"{score:.2f}", 
                            delta="High Alpha" if score > 0.5 else "Low",
                            help="Difference between Inclusive and Exclusive Efficiency Scores")
                
                # Breakdown
                gs_incl = cp.get('GS_Score_Incl', 0.0)
                gs_excl = cp.get('GS_Score_Excl', 0.0)
                
                col2.metric("Efficiency (Included)", f"{gs_incl:.2f}", help="Sharpe of Abs Residuals (Full Period)")
                col3.metric("Efficiency (Excluded)", f"{gs_excl:.2f}", help="Sharpe of Abs Residuals (Ex-Earnings)")
                
                col4.metric("ë¶„ì„ëœ ì´ë²¤íŠ¸", f"{cp.get('Event_Count', 0)}íšŒ")
                col5.metric("Factor Model", "5-Factor" if 'MOM' in betas else "4-Factor")

                # 2. Beta Breakdown
                st.caption("Fama-French Multi-Factor Coefficients")
                b1, b2, b3, b4, b5 = st.columns(5)
                b1.metric("Market Beta", f"{betas.get('Market', 0.0):.2f}")
                b2.metric("Sector Beta", f"{betas.get('Sector', 0.0):.2f}")
                b3.metric("Size (SMB)", f"{betas.get('SMB', 0.0):.2f}")
                b4.metric("Value (HML)", f"{betas.get('HML', 0.0):.2f}")
                b5.metric("Mom (MOM)", f"{betas.get('MOM', 0.0):.2f}")
                
                st.divider()

                # 3. Comparative Analysis (New Section)
                st.subheader("âš–ï¸ Comparative Analysis: Earnings Contribution")
                st.caption("ì‹¤ì  í¬í•¨(Inclusive) vs ì œì™¸(Exclusive) íš¨ìœ¨ì„± ë¹„êµ")
                
                c1, c2, c3 = st.columns(3)
                
                with c1:
                    st.markdown("#### Inclusive (Full)")
                    st.metric("Mean Abs (Ann)", f"{cp.get('Mean_Incl',0)*100:.1f}%")
                    st.metric("Vol (Ann)", f"{cp.get('Vol_Incl',0)*100:.1f}%")
                    st.metric("Score", f"{gs_incl:.2f}")
                    
                with c2:
                    st.markdown("#### Exclusive (No Earnings)")
                    st.metric("Mean Abs (Ann)", f"{cp.get('Mean_Excl',0)*100:.1f}%")
                    st.metric("Vol (Ann)", f"{cp.get('Vol_Excl',0)*100:.1f}%")
                    st.metric("Score", f"{gs_excl:.2f}")
                    
                with c3:
                    st.markdown("#### Earnings Impact")
                    st.metric("Delta Score", f"{score:.2f}", 
                              delta="Positive" if score > 0 else "Negative")
                    st.info(f"ì‹¤ì  ê¸°ê°„ì´ í¬í•¨ë¨ìœ¼ë¡œì¨ ì ìˆ˜ê°€ **{score:+.2f}** ë§Œí¼ ë³€í™”í–ˆìŠµë‹ˆë‹¤.")

                # Comparative Chart (Bar)
                # ... (Keeping existing Bar Chart or removing?)
                # User asked for "Earning í¬í•¨ê³¼ ì œì™¸ ë¹„êµ".
                # Bar chart of Scores is good.
                # Adding Cumulative Line Chart is BETTER.
                
                # 1. Bar Chart (Scores)
                comp_df = pd.DataFrame({
                    'Condition': ['Inclusive (With Earnings)', 'Exclusive (Without Earnings)'],
                    'GS Score': [gs_incl, gs_excl]
                })
                fig_bar = px.bar(comp_df, x='Condition', y='GS Score', color='Condition', 
                                 title="Efficiency Score Comparison", text_auto='.2f')
                st.plotly_chart(fig_bar, use_container_width=True)
                
                # 2. Cumulative Equity Curve (The "Proof")
                st.subheader("ğŸ“ˆ Cumulative Alpha (Idiosyncratic Return)")
                st.caption("ì‹¤ì  ë°œí‘œ ê¸°ê°„ì´ ì¥ê¸° ì„±ê³¼ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì‹œê°í™”í•©ë‹ˆë‹¤.")
                
                if 'Series_Excl' in cp:
                    # Incl Series (Full Idio Return)
                    s_incl = df['Idio_Return'].fillna(0)
                    
                    # Excl Series 
                    # logic_idio returns Series_Excl which contains only non-event days.
                    # We need to reindex it to full index to plot, filling removed days with 0.0 (Cash)
                    s_excl = cp['Series_Excl'].reindex(df.index).fillna(0.0)
                    
                    # Cumulative Sum
                    cum_incl = s_incl.cumsum()
                    cum_excl = s_excl.cumsum()
                    
                    chart_data = pd.DataFrame({
                        'With Earnings (ì‹¤ì  í¬í•¨)': cum_incl,
                        'Without Earnings (ì‹¤ì  ì œì™¸)': cum_excl
                    })
                    
                    fig_line = px.line(chart_data, title="Cumulative Idiosyncratic Return (Alpha Accumulation)",
                                       labels={'value': 'Cum Residual Return', 'index': 'Date'})
                    # Provide clearer colors
                    fig_line.update_traces(line=dict(width=2))
                    st.plotly_chart(fig_line, use_container_width=True)
                    
                    diff_val = cum_incl.iloc[-1] - cum_excl.iloc[-1]
                    st.info(f"ğŸ’¡ **ë¶„ì„ ê²°ê³¼**: ì‹¤ì  ë°œí‘œ ê¸°ê°„ì„ í¬í•¨í–ˆì„ ë•Œ ëˆ„ì  ì„±ê³¼ê°€ **{diff_val*100:+.1f}%** ë” {'ì¢‹ìŠµë‹ˆë‹¤' if diff_val>0 else 'ë‚˜ì©ë‹ˆë‹¤'}.")
                else:
                    st.warning("ìƒì„¸ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

                st.divider()

                # 2. ì¸ì‚¬ì´íŠ¸ ë©”ì‹œì§€ (GS Delta Logic)
                if score > 0.5:
                    st.success(f"**ğŸ”¥ High Impact:** ì‹¤ì  ë°œí‘œê°€ ì´ ì¢…ëª©ì˜ ë³€ë™ì„± ëŒ€ë¹„ ìˆ˜ìµ íš¨ìœ¨ì„ í¬ê²Œ ë†’ì—¬ì¤ë‹ˆë‹¤. (Delta: +{score:.2f})")
                elif score < 0.1:
                    st.warning(f"**ğŸ›¡ï¸ Low Impact:** ì‹¤ì  ë°œí‘œë¥¼ ì œì™¸í•´ë„ íš¨ìœ¨ì„± ì°¨ì´ê°€ ê±°ì˜ ì—†ìŠµë‹ˆë‹¤.")
                
                st.divider()

                # 3. ê·¸ë˜í”„: Alpha vs Beta ë¶„í•´
                
                st.divider()


            else:
                 # Data Collection Failed (Detailed Feedback)
                 st.warning(f"âš ï¸ **'{ticker}' ë°ì´í„° ìˆ˜ì§‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.**")
                 st.markdown("""
                 **ê°€ëŠ¥í•œ ì›ì¸ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:**
                 1. **ì˜ëª»ëœ í‹°ì»¤**: ë¯¸êµ­ ì£¼ì‹ í‹°ì»¤ê°€ ë§ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”. (ì˜ˆ: ì‚¼ì„±ì „ì ì‚¬ìš© ë¶ˆê°€)
                 2. **ë°ì´í„° ì ‘ê·¼ ì°¨ë‹¨ (Yahoo Finance)**: ì§§ì€ ì‹œê°„ì— ë„ˆë¬´ ë§ì€ ìš”ì²­ì„ ë³´ë‚´ë©´ ì¼ì‹œì ìœ¼ë¡œ ì°¨ë‹¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. (ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„)
                 3. **ë°ì´í„° ë¶€ì¡±**: ìƒì¥ëœ ì§€ 3ë…„ ë¯¸ë§Œì¸ ì¢…ëª©ì´ê±°ë‚˜, ê±°ë˜ëŸ‰ì´ ë§¤ìš° ì ì€ ì¢…ëª©ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (Nasdaq ì†ŒìŠ¤ ì‚¬ìš© ì¤‘)
                 4. **ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜**: ì¸í„°ë„· ì—°ê²° ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.
                 """)
