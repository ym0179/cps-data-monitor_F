import streamlit as st
import pandas as pd
import plotly.express as px
import FinanceDataReader as fdr
import requests
import urllib3
from io import StringIO, BytesIO
from datetime import datetime, timedelta, date
import yfinance as yf
import feedparser
import numpy as np
import pytz
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import plotly.express as px
import seaborn as sns
from collections import Counter
import re

# [í•„ìˆ˜] ê°™ì€ í´ë”ì˜ etf.pyì—ì„œ í´ë˜ìŠ¤ ì„í¬íŠ¸
try:
    from etf import ActiveETFMonitor
    try:
        from etf_kiwoom import KiwoomETFMonitor
    except ImportError:
        KiwoomETFMonitor = None
except ImportError:
    st.error("âš ï¸ 'etf.py' íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê°™ì€ í´ë”ì— ë„£ì–´ì£¼ì„¸ìš”.")
    st.stop()

# [NEW] Helper for Earnings Idio Score
import plotly.graph_objects as go
try:
    import logic_idio
except ImportError:
    logic_idio = None

# [NEW] Crawler Logic Import
import logic_crawler

# [NEW] Earnings Logic Import
try:
    from logic_earnings import get_naver_consensus_change
except ImportError:
     pass # handling later

# ë³´ì•ˆ ì¸ì¦ì„œ ê²½ê³  ë¬´ì‹œ ë° SSL ê²€ì¦ ìš°íšŒ (Global Patch)
# ë³´ì•ˆ ì¸ì¦ì„œ ê²½ê³  ë¬´ì‹œ ë° SSL ê²€ì¦ ìš°íšŒ (Global Patch)
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# [FIX] RecursionError ë°©ì§€: ì´ë¯¸ íŒ¨ì¹˜ë˜ì—ˆëŠ”ì§€ í™•ì¸
if not getattr(requests.Session.request, "_patched", False):
    original_request = requests.Session.request
    def patched_request(self, method, url, *args, **kwargs):
        kwargs['verify'] = False
        return original_request(self, method, url, *args, **kwargs)
    
    patched_request._patched = True
    requests.Session.request = patched_request


# ---------------------------------------------------------
# 1. í˜ì´ì§€ ì„¤ì •
# ---------------------------------------------------------
st.set_page_config(
    page_title="MAS Strategy Dashboard",
    page_icon="mirae_icon.png",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ---------------------------------------------------------
# 2. ë°ì´í„° ìˆ˜ì§‘ ë° ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ---------------------------------------------------------

@st.cache_data(ttl=600)
def fetch_market_data():
    """ì‹œì¥ í•µì‹¬ ì§€í‘œ ìˆ˜ì§‘"""
    tickers = {
        "KOSPI": "^KS11", "S&P500": "^GSPC", "Nasdaq": "^IXIC", 
        "USD/KRW": "KRW=X", "US 10Y": "^TNX", "WTI Oil": "CL=F"
    }
    data_dict = {}
    history_dict = {}
    
    for name, code in tickers.items():
        try:
            obj = yf.Ticker(code)
            hist = obj.history(period="1y")
            if not hist.empty:
                current = hist['Close'].iloc[-1]
                prev = hist['Close'].iloc[-2]
                pct_change = ((current - prev) / prev) * 100
                hist['MA20'] = hist['Close'].rolling(window=20).mean()
                trend = "ìƒìŠ¹" if current > hist['MA20'].iloc[-1] else "í•˜ë½"
                data_dict[name] = {"price": current, "pct_change": pct_change, "trend": trend}
                history_dict[name] = hist
        except: continue
    return data_dict, history_dict

def to_excel(df_new, df_inc, df_dec, df_all, date):
    output = BytesIO()
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        df_new.to_excel(writer, index=False, sheet_name='ì‹ ê·œí¸ì…')
        df_inc.to_excel(writer, index=False, sheet_name='ë¹„ì¤‘í™•ëŒ€')
        df_dec.to_excel(writer, index=False, sheet_name='ë¹„ì¤‘ì¶•ì†Œ')
        df_all.to_excel(writer, index=False, sheet_name='ì „ì²´í¬íŠ¸í´ë¦¬ì˜¤')
    return output.getvalue()



def fetch_yahoo_news(tickers):
    """Yahoo Finance ë‰´ìŠ¤ ìˆ˜ì§‘ (ë” ì‹ ë¢°ë„ ë†’ì€ ì†ŒìŠ¤)"""
    news_items = []
    try:
        # ì—¬ëŸ¬ í‹°ì»¤ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬
        for ticker in tickers:
            stock = yf.Ticker(ticker)
            news = stock.news
            if news:
                for n in news:
                    # YF ë‰´ìŠ¤ êµ¬ì¡°: title, link, providerPublishTime, publisher
                    pub_time = n.get('providerPublishTime', 0)
                    dt = datetime.fromtimestamp(pub_time)
                    
                    news_items.append({
                        "title": n.get('title', ''),
                        "link": n.get('link', ''),
                        "published_dt": dt,
                        "published": dt.strftime("%Y-%m-%d %H:%M"),
                        "source": f"Yahoo ({n.get('publisher', 'Unknown')})"
                    })
    except Exception as e:
        # st.error(f"Yahoo News Error: {e}") # ë””ë²„ê¹…ìš©
        pass
        
    return news_items

@st.cache_data(ttl=3600)
def fetch_trending_tickers():
    """Yahoo Finance Trending Tickers ê°€ì ¸ì˜¤ê¸°"""
    trending = []
    try:
        # Yahoo Finance Trending Endpoint (US Region)
        url = "https://query1.finance.yahoo.com/v1/finance/trending/US?count=10"
        headers = {'User-Agent': 'Mozilla/5.0'}
        resp = requests.get(url, headers=headers, verify=False) # SSL false per user env
        data = resp.json()
        
        result = data['finance']['result'][0]['quotes']
        for item in result:
             symbol = item['symbol']
             trending.append(symbol)
             
    except Exception as e:
        pass
    return trending

@st.cache_data(ttl=3600)
def fetch_kdi_keywords():
    """KDI ê²½ì œ ì •ë³´ ì„¼í„° - ê²½ì œ í‚¤ì›Œë“œ íŠ¸ë Œë“œ í¬ë¡¤ë§"""
    keywords = []
    try:
        url = "https://eiec.kdi.re.kr/bigdata/issueTrend.do"
        headers = {'User-Agent': 'Mozilla/5.0'}
        # KDI ì‚¬ì´íŠ¸ëŠ” SSL ê²€ì¦ì´ í•„ìš”í•  ìˆ˜ ìˆìœ¼ë‚˜, ì‚¬ìš©ì í™˜ê²½ ê³ ë ¤ False
        resp = requests.get(url, headers=headers, verify=False)
        html = resp.text
        
        # ì •ê·œì‹ìœ¼ë¡œ [í‚¤ì›Œë“œ](javascript:;) íŒ¨í„´ ì¶”ì¶œ
        # ì˜ˆ: [ì›ë‹¬ëŸ¬í™˜ìœ¨](javascript:;)
        # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•´ ë¦¬ìŠ¤íŠ¸ ëŒ€ì‹  ì§‘í•© ì‚¬ìš© í›„ ë‹¤ì‹œ ë¦¬ìŠ¤íŠ¸ë¡œ
        found = re.findall(r'\[(.*?)\]\(javascript:;\)', html)
        
        # ìˆœì„œ ìœ ì§€ë¥¼ ìœ„í•´ dict.fromkeys ì‚¬ìš© (Python 3.7+)
        keywords = list(dict.fromkeys(found))
        
        # ìƒìœ„ 20ê°œë§Œ
        return keywords[:20]
        
    except Exception as e:
        # st.error(f"KDI Fetch Error: {e}")
        return []

@st.cache_data(ttl=3600)
def fetch_global_events():
    """ì „ì²´ ì‹œì¥ í•µì‹¬ ì´ë²¤íŠ¸ ìˆ˜ì§‘ (Google News + Yahoo Finance)"""
    market_news = []
    
    # 1. Yahoo Finance (ì‹ ë¢°ì˜¤ ì†ŒìŠ¤ ìš°ì„  - SPY, QQQ, NVDA)
    market_news.extend(fetch_yahoo_news(["SPY", "QQQ", "^DJI"]))
    
    # 2. Google News (ë³´ì¡°)
    # ê´‘ë²”ìœ„í•œ ì‹œì¥ í‚¤ì›Œë“œ
    query = "stock market live updates Fed CPI inflation earnings report when:3d"
    encoded = requests.utils.quote(query)
    url = f"https://news.google.com/rss/search?q={encoded}&hl=en-US&gl=US&ceid=US:en"
    
    try:
        feed = feedparser.parse(url)
        for e in feed.entries:
            # ë‚ ì§œ íŒŒì‹±
            if hasattr(e, 'published_parsed') and e.published_parsed:
                dt = datetime(*e.published_parsed[:6])
            else:
                dt = datetime.now()

            market_news.append({
                "title": e.title,
                "link": e.link,
                "published": e.published,
                "published_dt": dt, # ì •ë ¬ìš©
                "source": e.source.title if hasattr(e, 'source') else "News"
            })
    except: pass
    
    # ì¤‘ë³µ ì œê±° (Link ê¸°ì¤€) & ì •ë ¬
    seen_links = set()
    unique_news = []
    for n in market_news:
        if n['link'] not in seen_links:
            unique_news.append(n)
            seen_links.add(n['link'])
            
    # ìµœì‹ ìˆœ ì •ë ¬
    unique_news.sort(key=lambda x: x['published_dt'], reverse=True)
    
    return unique_news[:7] # Top 7 (ì•¼í›„ ì¶”ê°€ë¡œ ê°œìˆ˜ ëŠ˜ë¦¼)

@st.cache_data(ttl=3600)
def fetch_ib_news(bank_name):
    """ì£¼ìš” IBë“¤ì˜ ìµœì‹  ë§ˆì¼“ ì½”ë©˜íŠ¸ ìˆ˜ì§‘ (Google News + Yahoo Finance)"""
    ib_news = []
    
    # 1. Yahoo Finance (í‹°ì»¤ ë§¤í•‘)
    ticker_map = {
        "JP Morgan": "JPM",
        "Goldman Sachs": "GS",
        "Morgan Stanley": "MS"
    }
    
    if bank_name in ticker_map:
        ib_news.extend(fetch_yahoo_news([ticker_map[bank_name]]))

    # 2. Google News RSS
    # ê²€ìƒ‰ì–´ ìµœì í™”: "BankName market outlook 2025" or "BankName stock strategy" relative to last 30 days
    query = f"{bank_name} market outlook strategy forecast when:30d"
    encoded = requests.utils.quote(query)
    url = f"https://news.google.com/rss/search?q={encoded}&hl=en-US&gl=US&ceid=US:en"
    
    try:
        feed = feedparser.parse(url)
        for e in feed.entries:
            # ë‚ ì§œ íŒŒì‹±
            if hasattr(e, 'published_parsed') and e.published_parsed:
                dt = datetime(*e.published_parsed[:6])
            else:
                dt = datetime.now()

            ib_news.append({
                "title": e.title,
                "link": e.link,
                "published": e.published,
                "published_dt": dt,
                "source": e.source.title if hasattr(e, 'source') else "News"
            })
    except: pass
    
    # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
    seen_titles = set()
    unique_news = []
    for n in ib_news:
        # ì œëª©ì´ ë„ˆë¬´ ë¹„ìŠ·í•˜ë©´ ì¤‘ë³µ ì²˜ë¦¬ (ê°„ë‹¨í•œ ë¡œì§)
        title_summary = n['title'][:30]
        if title_summary not in seen_titles:
            unique_news.append(n)
            seen_titles.add(title_summary)
            
    # ìµœì‹ ìˆœ ì •ë ¬
    unique_news.sort(key=lambda x: x['published_dt'], reverse=True)
    
    return unique_news[:5] # Top 5

def get_news_tags(title):
    """ë‰´ìŠ¤ ì œëª© ê¸°ë°˜ íƒœê·¸ ìƒì„± (NLP-lite)"""
    title_lower = title.lower()
    tags = []
    
    # 1. Momentum (Positive)
    if any(k in title_lower for k in ["upgrade", "buy", "bull", "overweight", "raise", "top pick", "growth", "positive", "hike"]):
        tags.append(("ğŸš€ Momentum", "#FFEAEA", "#FF0000")) # Text, BG, Color
        
    # 2. Risk (Negative)
    if any(k in title_lower for k in ["downgrade", "sell", "bear", "underweight", "cut", "risk", "warn", "negative", "slow", "recession"]):
        tags.append(("âš ï¸ Risk", "#EAEFFF", "#0000FF"))
        
    # 3. Key Event (Neutral/Impact)
    if any(k in title_lower for k in ["fed", "rate", "cpi", "inflation", "earnings", "policy", "meeting", "tech", "ai "]):
        tags.append(("ğŸ“¢ Event", "#F2F2F2", "#333333"))
        
    return tags

def calculate_super_theme(df, ref_date=None):
    """ìŠˆí¼í…Œë§ˆ ETF ìˆ˜ìµë¥  ë° ë³€ë™ì„± ê³„ì‚° (FDR ì‚¬ìš©)"""
    results = []
    
    if ref_date is None:
        ref_date = datetime.now()
    
    end_date_str = ref_date.strftime("%Y-%m-%d")
    # 60D ë³€ë™ì„± ê³„ì‚°ì„ ìœ„í•´ ë„‰ë„‰í•œ ë°ì´í„° í•„ìš” (ì•½ 4~5ê°œì›”)
    start_date_str = (ref_date - timedelta(days=150)).strftime("%Y-%m-%d")
    
    for i, row in df.iterrows():
        ticker = str(row['Ticker']).strip()
        if ticker.endswith('.KS'): ticker = ticker.replace('.KS', '')
        
        try:
            hist = fdr.DataReader(ticker, start_date_str, end_date_str)
            
            if not hist.empty:
                curr = hist['Close'].iloc[-1]
                
                # Returns (Round to 1 decimal)
                ret_1d = ((curr - hist['Close'].iloc[-2]) / hist['Close'].iloc[-2] * 100) if len(hist) >= 2 else 0
                ret_5d = ((curr - hist['Close'].iloc[-6]) / hist['Close'].iloc[-6] * 100) if len(hist) >= 6 else 0
                # 1M = 20 trading days
                ret_1m = ((curr - hist['Close'].iloc[-21]) / hist['Close'].iloc[-21] * 100) if len(hist) >= 21 else 0
                
                # VOL_60D Calculation (Annualized Volatility of last 60 days)
                # Formula: StdDev(Daily Returns of last 60 days) * sqrt(252) * 100
                if len(hist) > 60:
                    recent_60 = hist['Close'].iloc[-61:] # Get 61 points to have 60 returns
                    daily_ret = recent_60.pct_change().dropna()
                    vol_60d = daily_ret.std() * (252 ** 0.5) * 100
                else:
                    vol_60d = 0

                # Get Score from Input DF if exists, else 0
                score = row.get('Score', 0)
                
                results.append({
                    "Ticker": row['Ticker'],
                    "Name": row['Name'],
                    "Theme": row['Theme'],
                    "Score": score, # Scoring provided by user
                    "1D": round(ret_1d, 1),
                    "5D": round(ret_5d, 1),
                    "1M": round(ret_1m, 1),
                    "VOL_60D": round(vol_60d, 1)
                })
            else:
                 st.warning(f"{ticker}: ë°ì´í„° ì—†ìŒ")
        except Exception as e:
            st.error(f"{ticker} ì—ëŸ¬: {e}")
    
    if not results:
        return pd.DataFrame(columns=["Ticker", "Name", "Theme", "Score", "1D", "5D", "1M", "VOL_60D"])
    
    return pd.DataFrame(results)

def calculate_super_stock(df, ref_date=None):
    """ìŠˆí¼ìŠ¤íƒ ë°ì´í„° ê³„ì‚° (Mkt.Cap, Score, Multiples í¬í•¨)"""
    results = []
    
    if ref_date is None:
        ref_date = datetime.now()
        
    end_date_str = ref_date.strftime("%Y-%m-%d")
    start_date_str = (ref_date - timedelta(days=10)).strftime("%Y-%m-%d")

    for i, row in df.iterrows():
        ticker = str(row['Ticker']).strip()
        if ticker.endswith('.KS'): ticker = ticker.replace('.KS', '')
        
        try:
            # FDR is used mainly to verify ticker is active, or we could skip if we trust input.
            # But let's fetch to ensure we're aligned with market.
            # Actually, user wants "Organize by MktCap, Score...". 
            # If we don't fetch price, we can't show "Change". 
            # But user request focused on "Mkt.Cap, score, PER, PEG".
            # Input DF already has these from universe.xslx via `update_universe.py`.
            
            # Fetch price just for validity check
            # hist = fdr.DataReader(ticker, start_date_str, end_date_str)
            
            results.append({
                "Ticker": row['Ticker'],
                "Name": row['Name'],
                "Sector": row['Sector'],
                "Mkt.Cap($bn)": row.get('MktGap', 0), # MktGap column from make_universe
                "Score": row.get('Score', 0),
                "PER": row.get('PER', 0),
                "PEG": row.get('PEG', 0)
            })
        except: pass
        
    return pd.DataFrame(results)

@st.cache_data(ttl=86400)
def fetch_statcounter_data(metric="search_engine", device="desktop+mobile+tablet+console", region="ww", from_year="2019", from_month="01", to_year=None, to_month=None):
    """StatCounter ë°ì´í„° ìˆ˜ì§‘ (CSV Direct)"""
    import requests
    import io
    from datetime import datetime
    
    # to_year/to_monthê°€ ì—†ìœ¼ë©´ í˜„ì¬ ì‹œê°„ ê¸°ì¤€
    if to_year is None or to_month is None:
        now = datetime.now()
        to_year = now.year
        to_month = now.month
    
    base_url = "https://gs.statcounter.com/chart.php"
    
    # device íŒŒë¼ë¯¸í„° ì²˜ë¦¬
    # device_hidden ê°’ ì„¤ì • (StatCounterëŠ” device_hiddenì„ ì£¼ë¡œ ì‚¬ìš©)
    device_val = device
    
    # metric ì„¤ì •
    if metric == "search_engine":
        stat_type_hidden = "search_engine"
        stat_type_label = "Search Engine"
    elif metric == "os":
        stat_type_hidden = "os_combined"
        stat_type_label = "OS Market Share"
    elif metric == "browser":
        stat_type_hidden = "browser"
        stat_type_label = "Browser"
        
    params = {
        "device": device, # Label text but utilizing same val for simplicity or need map? 
        # Actually StatCounter url uses 'device' param for label and 'device_hidden' for value.
        # But 'device' param in getting csv might be loose. Let's use correct hidden val.
        "device_hidden": device_val, 
        "multi-device": "true",
        "statType_hidden": stat_type_hidden,
        "region_hidden": region,
        "granularity": "monthly",
        "statType": stat_type_label,
        "region": "Worldwide",
        "fromInt": f"{from_year}{from_month}",
        "toInt": f"{to_year}{to_month:02d}",
        "fromMonthYear": f"{from_year}-{from_month}",
        "toMonthYear": f"{to_year}-{to_month:02d}",
        "csv": "1"
    }
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }
    
    try:
        response = requests.get(base_url, params=params, headers=headers, verify=False)
        if response.status_code == 200:
            df = pd.read_csv(io.StringIO(response.text))
            # ë‚ ì§œë¥¼ YYYY-MM í˜•ì‹ì˜ ë¬¸ìì—´ë¡œ ë³€í™˜
            df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m')
            df.set_index('Date', inplace=True)
            return df
        else:
            return pd.DataFrame()
    except Exception as e:
        st.error(f"ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜: {e}")
        return pd.DataFrame()

def process_search_engine_data(df):
    """Google, Bing, Yahoo, Other 4íŒŒì „ìœ¼ë¡œ ì •ë¦¬"""
    if df.empty:
        return df
        
    # CSV header might be 'bing' or 'Bing', 'Yahoo!' or 'Yahoo'
    cols = df.columns
    
    # Bing ì´ë¦„ í™•ì¸
    bing_col = 'bing' if 'bing' in cols else 'Bing'
    # Yahoo ì´ë¦„ í™•ì¸
    yahoo_col = 'Yahoo!' if 'Yahoo!' in cols else 'Yahoo'
    
    final_targets = ['Google', bing_col, yahoo_col]
    
    # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
    valid_targets = [c for c in final_targets if c in cols]
    
    # Other ê³„ì‚°
    other_cols = [c for c in cols if c not in valid_targets]
    
    df_processed = df[valid_targets].copy()
    if other_cols:
        df_processed['Other'] = df[other_cols].sum(axis=1)
    
    # ì´ë¦„ í†µì¼
    rename_map = {}
    if yahoo_col in df_processed.columns:
        rename_map[yahoo_col] = 'Yahoo'
    if bing_col in df_processed.columns:
        rename_map[bing_col] = 'Bing'
        
    if rename_map:
        df_processed.rename(columns=rename_map, inplace=True)
        
    # ìš”ì²­ëœ ìˆœì„œë¡œ ì •ë ¬: Google, Yahoo, Other, Bing
    desired_order = ['Google', 'Yahoo', 'Other', 'Bing']
    # ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ í•„í„°ë§í•˜ì—¬ ìˆœì„œ ì ìš©
    final_order = [c for c in desired_order if c in df_processed.columns]
    
    return df_processed[final_order]

# ë°ì´í„° ë¡œë“œ
macro_metrics, macro_histories = fetch_market_data()

# ---------------------------------------------------------
# 3. ì‚¬ì´ë“œë°” êµ¬ì„±
# ---------------------------------------------------------
with st.sidebar:
    import os
    if os.path.exists("mirae_icon.png"):
        st.image("mirae_icon.png", use_container_width=True)
    else:
        st.title("ğŸŠ Mirae Asset")
    st.subheader("ê³ ê°ìì‚°ë°°ë¶„ë³¸ë¶€ ê³ ê°ìƒí’ˆì „ëµíŒ€")
    st.caption("Strategy Dashboard V4.1")
    st.markdown("---")
    
    menu = st.radio("ë©”ë‰´ ì„ íƒ", [
        "ğŸ“ˆ MS Monitoring",
        "ğŸ’ Earnings Event Trading",
        "ğŸ“Š Active ETF Analysis"
    ])
    
    # logic_backtest removed as redundant
    
    if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨"):
        st.cache_data.clear()
        st.rerun()

# ---------------------------------------------------------
# 4. ë©”ì¸ í™”ë©´ ë¡œì§
# ---------------------------------------------------------

# [TAB 2] Super-Stock (StatCounter) - íŒ€ì¥ë‹˜ ê°œì¸ ì—…ë¬´
if menu == "ğŸ“ˆ MS Monitoring":
    st.header("ğŸ“ˆ MS Monitoring (Global Market Share)")
    st.caption("Data Source: StatCounter Global Stats")
    
    # ë©”ì¸ íƒ­ ë¶„ë¦¬: ê²€ìƒ‰ì—”ì§„ vs ëª¨ë°”ì¼ OS
    main_tab1, main_tab2 = st.tabs(["ğŸ” Browser Market Share ", "ğŸ“± Operating System Market Share"])
    
    # [Tab 1] ê²€ìƒ‰ì—”ì§„ (ê¸°ì¡´ ê¸°ëŠ¥)
    with main_tab1:
        st.subheader("Global Browser Market Share")
        st.caption("Google vs Bing vs Yahoo vs Other")
        
        sub_tab1, sub_tab2, sub_tab3 = st.tabs(["ğŸ–¥ï¸+ğŸ“± Desktop & Mobile", "ğŸ–¥ï¸ Desktop", "ğŸ“± Mobile"])
        
        # 1. Desktop + Mobile (Combined)
        with sub_tab1:
            df = fetch_statcounter_data("search_engine", device="desktop+mobile")
            df_proc = process_search_engine_data(df)
            
            if not df_proc.empty:
                # ë§‰ëŒ€ ì°¨íŠ¸ (Stacked Bar)
                fig = px.bar(df_proc, title="Search Engine M/S (Total)", barmode='stack', 
                             color_discrete_map={'Google': '#4285F4', 'Bing': '#00A4EF', 'Yahoo': '#7B0099', 'Other': '#999999'})
                
                # Yì¶• ìŠ¤ì¼€ì¼ ì¡°ì • (0~100 ê³ ì •)
                fig.update_layout(yaxis_range=[0, 100], legend=dict(orientation="h", yanchor="top", y=-0.2, xanchor="center", x=0.5))
                
                st.plotly_chart(fig, use_container_width=True)
                st.dataframe(df_proc.sort_index(ascending=False).style.format("{:.1f}%").background_gradient(cmap="Reds", subset=["Google"]), use_container_width=True)

        # 2. Desktop
        with sub_tab2:
            df = fetch_statcounter_data("search_engine", device="desktop")
            df_proc = process_search_engine_data(df)
            
            if not df_proc.empty:
                fig = px.bar(df_proc, title="Search Engine M/S (Desktop)", barmode='stack',
                             color_discrete_map={'Google': '#4285F4', 'Bing': '#00A4EF', 'Yahoo': '#7B0099', 'Other': '#999999'})
                
                # Yì¶• ìŠ¤ì¼€ì¼ ì¡°ì • (0~100 ê³ ì •)
                fig.update_layout(yaxis_range=[0, 100], legend=dict(orientation="h", yanchor="top", y=-0.2, xanchor="center", x=0.5))

                st.plotly_chart(fig, use_container_width=True)
                st.dataframe(df_proc.sort_index(ascending=False).style.format("{:.1f}%").background_gradient(cmap="Reds", subset=["Google"]), use_container_width=True)

        # 3. Mobile
        with sub_tab3:
            df = fetch_statcounter_data("search_engine", device="mobile")
            df_proc = process_search_engine_data(df)
            
            if not df_proc.empty:
                fig = px.bar(df_proc, title="Search Engine M/S (Mobile)", barmode='stack',
                             color_discrete_map={'Google': '#4285F4', 'Bing': '#00A4EF', 'Yahoo': '#7B0099', 'Other': '#999999'})
                
                # Yì¶• ìŠ¤ì¼€ì¼ ì¡°ì • (0~100 ê³ ì •)
                fig.update_layout(yaxis_range=[0, 100], legend=dict(orientation="h", yanchor="top", y=-0.2, xanchor="center", x=0.5))

                st.plotly_chart(fig, use_container_width=True)
                st.dataframe(df_proc.sort_index(ascending=False).style.format("{:.1f}%").background_gradient(cmap="Reds", subset=["Google"]), use_container_width=True)

    # [Tab 2] OS Rivalry (New Feature)
    with main_tab2:
        st.subheader("ğŸ“± Mobile & Tablet OS Rivalry (Android vs iOS)")
        st.caption("Which ecosystem is winning? (Data since 2009)")
        
        # ì»¨íŠ¸ë¡¤ íŒ¨ë„
        c1, c2 = st.columns([1, 1])
        with c1:
            os_device = st.radio("Platform", ["Mobile", "Tablet", "Mobile + Tablet"], horizontal=True)
            # íŒŒë¼ë¯¸í„° ë§¤í•‘
            device_param_map = {
                "Mobile": "mobile",
                "Tablet": "tablet",
                "Mobile + Tablet": "mobile+tablet"
            }
            target_device = device_param_map[os_device]
            
        with c2:
            # ì—°ë„ ë¦¬ìŠ¤íŠ¸ ìƒì„± (í˜„ì¬ ì—°ë„ ~ 2009)
            current_year = datetime.now().year
            year_options = [str(y) for y in range(current_year, 2008, -1)]
            period_options = ["Last 12 Months"] + year_options + ["All Time"]
            period = st.selectbox("Period", period_options)
            
        # ë°ì´í„° ìˆ˜ì§‘ (2009ë…„ë¶€í„° ìµœëŒ€ì¹˜)
        # í†µì‹  ì—ëŸ¬ ë°©ì§€ìš© ì˜ˆì™¸ì²˜ë¦¬
        try:
            df_os = fetch_statcounter_data("os", device=target_device, from_year="2009", from_month="01")
        except Exception:
            df_os = pd.DataFrame()
        
        if not df_os.empty:
            # Android, iOS, iPadOS í•„í„°ë§
            targets = ['Android', 'iOS', 'iPadOS']
            # ì‹¤ì œ ì»¬ëŸ¼ëª… í™•ì¸ (ëŒ€ì†Œë¬¸ì ì´ìŠˆ ë°©ì§€)
            valid_targets = []
            rename_map = {}
            for t in targets:
                # ëŒ€ì†Œë¬¸ì ë¬´ì‹œí•˜ê³  ì°¾ê¸°
                for col in df_os.columns:
                    if t.lower() == col.lower():
                        valid_targets.append(col)
                        rename_map[col] = t # í‘œì¤€ ì´ë¦„ìœ¼ë¡œ ë§¤í•‘
                        break
            
            if len(valid_targets) > 0:
                df_final = df_os[valid_targets].copy()
                df_final.rename(columns=rename_map, inplace=True)
                
                # ë‚ ì§œ ì˜¤ë¦„ì°¨ìˆœ ì •ë ¬ (iloc ìŠ¬ë¼ì´ì‹±ì„ ìœ„í•´ í•„ìˆ˜)
                df_final.sort_index(ascending=True, inplace=True)
                
                # ê¸°ê°„ í•„í„°ë§
                if period == "Last 12 Months":
                    df_final = df_final.iloc[-13:] # User Request: 2024-12 ~ 2025-12 (13 months)
                elif period == "All Time":
                    pass
                elif period.isdigit(): # "2025", "2024" etc.
                    df_final = df_final[df_final.index.str.startswith(period)]
                
                # ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì•ˆë‚´
                if df_final.empty:
                    st.warning(f"ì„ íƒí•˜ì‹  ê¸°ê°„({period})ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    # Tooltip ì •ë ¬ì„ ìœ„í•´ ë§ˆì§€ë§‰ ë°ì´í„° ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ì»¬ëŸ¼ ì¬ì •ë ¬
                    # (User Request: ë†’ì´ ìˆëŠ” ìˆ«ìë‘ ì¢…ë¥˜ë¶€í„° ëœ¨ê²Œ)
                    last_row = df_final.iloc[-1]
                    sorted_cols = last_row.sort_values(ascending=False).index.tolist()
                    df_final = df_final[sorted_cols]
                
                # êº¾ì€ì„  ì°¨íŠ¸ (Line Chart)
                # ë°ì´í„° í¬ì¸íŠ¸ê°€ ë§ìœ¼ë©´ ë§ˆì»¤ë¥¼ ìˆ¨ê²¨ì„œ ê¹”ë”í•˜ê²Œ (20ê°œ ë¯¸ë§Œì¼ ë•Œë§Œ í‘œì‹œ)
                show_markers = True if len(df_final) < 20 else False
                
                # ìƒ‰ìƒ ì„¤ì • (User Request: StatCounter Style - Android Orange, iOS Gray)
                colors = {'Android': '#F48024', 'iOS': '#555555', 'iPadOS': '#555555'}
                
                fig = px.line(df_final, title=f"OS Market Share ({os_device}) - {period}", 
                              color_discrete_map=colors,
                              markers=show_markers) 
                
                # ë¼ì¸ ë‘ê»˜ ì„¤ì •
                fig.update_traces(line=dict(width=3))
                
                # ë¼ì¸ ë‘ê»˜ ì„¤ì •
                fig.update_traces(line=dict(width=3))
                
                # Yì¶• & Range Slider ì„¤ì •
                fig.update_layout(
                    # yaxis_range=[0, 100], # ê³ ì • ë²”ìœ„ ì œê±° (Autoë¡œ ì´ë¯¸ì§€ì²˜ëŸ¼ Zoom íš¨ê³¼)
                    yaxis=dict(rangemode='tozero'), # 0ë¶€í„° ì‹œì‘í•˜ë„ë¡ ê°•ì œ
                    xaxis=dict(
                        rangeslider=dict(visible=False), # ìš”ì²­ëŒ€ë¡œ ì œê±°
                        type="date"
                    ),
                    legend=dict(orientation="h", yanchor="top", y=-0.2, xanchor="center", x=0.5),
                    hovermode="x", # User Request: ìˆ˜ì¹˜ë¥¼ ë”°ë¡œ í‘œì‹œ (Separate)
                    plot_bgcolor='white' # ì´ë¯¸ì§€ì²˜ëŸ¼ ë°°ê²½ ê¹”ë”í•˜ê²Œ
                )
                fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='#E5E5E5')
                fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='#E5E5E5') # ê²©ì í‘œì‹œ
                
                st.plotly_chart(fig, use_container_width=True)
                
                # ë°ì´í„° í…Œì´ë¸”
                st.markdown("### ğŸ“Š Monthly Data")
                st.dataframe(df_final.sort_index(ascending=False).style.format("{:.1f}%"), use_container_width=True)
            else:
                st.warning("Android ë˜ëŠ” iOS ë°ì´í„°ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        else:
            st.error("ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")


# [TAB 3] TIMEFOLIO Analysis (ê²½ìŸì‚¬ ë¶„ì„)
# [TAB 3] (Validator Removed)

if menu == "ğŸ“Š Active ETF Analysis":
    st.title("ğŸ“Š Active ETF Daily Rebalancing")
    
    # Provider Selection
    provider = st.radio("ìš´ìš©ì‚¬ ì„ íƒ", ["TIMEFOLIO (íƒ€ì„í´ë¦¬ì˜¤)", "KIWOOM (í‚¤ì›€ - KOSEF)"], horizontal=True)
    
    if "KIWOOM" in provider:
        st.info("ğŸ“Œ **ëŒ€ìƒ ì¢…ëª©:** KOSEF ë¯¸êµ­ì„±ì¥ê¸°ì—…30 Active (459790)")
        
        if KiwoomETFMonitor is None:
             st.error("Kiwoom ëª¨ë“ˆì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
             # Date Selection
             col_date, col_btn = st.columns([2, 1])
             with col_date:
                 target_date = st.date_input("ì¡°íšŒí•  ë‚ ì§œ ì„ íƒ", datetime.now(pytz.timezone('Asia/Seoul')))
             with col_btn:
                 st.write("") 
                 st.write("")
                 run_btn = st.button("ë¦¬ë°¸ëŸ°ì‹± ë¶„ì„ ì¡°íšŒ ğŸ”")
             
             if run_btn:
                 with st.spinner(f"{target_date} ë°ì´í„° ë° ì´ì „ ì˜ì—…ì¼ ë¹„êµ ë¶„ì„ ì¤‘..."):
                     try:
                         mon = KiwoomETFMonitor()
                         t_date_str = target_date.strftime("%Y-%m-%d")
                         
                         # Data Fetch
                         df_curr = mon.get_portfolio_data(t_date_str)
                         prev_day = mon.get_previous_business_day(t_date_str)
                         
                         if df_curr.empty:
                             st.warning(f"âš ï¸ {t_date_str} ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                             st.stop()
                             
                         # Analysis
                         if prev_day:
                             df_prev = mon.load_data(prev_day)
                             analysis = mon.analyze_rebalancing(df_curr, df_prev)
                             
                             st.success(f"âœ… ë¶„ì„ ì™„ë£Œ (ë¹„êµ: {t_date_str} vs {prev_day})")
                             
                             # --- Dashboard UI (4 Quadrants) ---
                             
                             # 1. Summary Metrics
                             m1, m2, m3, m4 = st.columns(4)
                             m1.metric("ë¹„ì¤‘ í™•ëŒ€", f"{len(analysis['increased_stocks'])} ì¢…ëª©")
                             m2.metric("ë¹„ì¤‘ ì¶•ì†Œ", f"{len(analysis['decreased_stocks'])} ì¢…ëª©")
                             m3.metric("ì‹ ê·œ í¸ì…", f"{len(analysis['new_stocks'])} ì¢…ëª©")
                             m4.metric("ì™„ì „ í¸ì¶œ", f"{len(analysis['removed_stocks'])} ì¢…ëª©")
                             
                             st.markdown("---")
                             
                             # 2. Quadrants
                             # Row 1: New & Removed
                             c1, c2 = st.columns(2)
                             with c1:
                                 st.markdown("##### ğŸŸ¢ ì‹ ê·œ í¸ì… (New)")
                                 if analysis['new_stocks']:
                                     new_df = pd.DataFrame(analysis['new_stocks'])
                                     # Show Name, Weight, Weight Change
                                     disp = new_df[['ì¢…ëª©ëª…', 'ë¹„ì¤‘_today', 'ë¹„ì¤‘ë³€í™”']].copy()
                                     disp.columns = ['ì¢…ëª©ëª…', 'ë¹„ì¤‘', 'ë¹„ì¤‘ë³€ë™']
                                     disp['ë¹„ì¤‘'] = disp['ë¹„ì¤‘'].apply(lambda x: f"{x:.2f}%")
                                     disp['ë¹„ì¤‘ë³€ë™'] = disp['ë¹„ì¤‘ë³€ë™'].apply(lambda x: f"+{x:.2f}%p")
                                     st.dataframe(disp, hide_index=True, use_container_width=True)
                                 else:
                                     st.info("ì‹ ê·œ í¸ì… ì¢…ëª© ì—†ìŒ")
                                     
                             with c2:
                                 st.markdown("##### ğŸ”´ ì™„ì „ í¸ì¶œ (Removed)")
                                 if analysis['removed_stocks']:
                                     rem_df = pd.DataFrame(analysis['removed_stocks'])
                                     # Show Name, Prev Weight, Weight Change
                                     disp = rem_df[['ì¢…ëª©ëª…', 'ë¹„ì¤‘_prev', 'ë¹„ì¤‘ë³€í™”']].copy()
                                     disp.columns = ['ì¢…ëª©ëª…', 'ì´ì „ë¹„ì¤‘', 'ë¹„ì¤‘ë³€ë™']
                                     disp['ì´ì „ë¹„ì¤‘'] = disp['ì´ì „ë¹„ì¤‘'].apply(lambda x: f"{x:.2f}%")
                                     disp['ë¹„ì¤‘ë³€ë™'] = disp['ë¹„ì¤‘ë³€ë™'].apply(lambda x: f"{x:.2f}%p")
                                     st.dataframe(disp, hide_index=True, use_container_width=True)
                                 else:
                                     st.info("ì™„ì „ í¸ì¶œ ì¢…ëª© ì—†ìŒ")
                                     
                             # Row 2: Increased & Decreased (Top 5)
                             c3, c4 = st.columns(2)
                             with c3:
                                 st.markdown("##### ğŸ”¼ ë¹„ì¤‘ í™•ëŒ€ (Top 5)")
                                 if analysis['increased_stocks']:
                                     inc_df = pd.DataFrame(analysis['increased_stocks'])
                                     # Sort by Share Change? Or Weight Change?
                                     # User asked "ë¹„ì¤‘í™•ëŒ€". Usually sorted by magnitude.
                                     # Kiwoom analysis sorts by 'ìˆ˜ëŸ‰ë³€í™”' internally for 'Increased', but let's sort display by 'ë¹„ì¤‘ë³€í™”' for consistency with "Weight" focus?
                                     # Or stick to Share Change sort but display Weight?
                                     # I'll sort by 'ë¹„ì¤‘ë³€í™”' descending.
                                     inc_df = inc_df.sort_values('ë¹„ì¤‘ë³€í™”', ascending=False).head(5)
                                     
                                     disp = inc_df[['ì¢…ëª©ëª…', 'ë¹„ì¤‘_today', 'ë¹„ì¤‘ë³€í™”']].copy()
                                     disp.columns = ['ì¢…ëª©ëª…', 'í˜„ì¬ë¹„ì¤‘', 'ë¹„ì¤‘ë³€ë™']
                                     disp['í˜„ì¬ë¹„ì¤‘'] = disp['í˜„ì¬ë¹„ì¤‘'].apply(lambda x: f"{x:.2f}%")
                                     disp['ë¹„ì¤‘ë³€ë™'] = disp['ë¹„ì¤‘ë³€ë™'].apply(lambda x: f"+{x:.2f}%p")
                                     st.dataframe(disp, hide_index=True, use_container_width=True)
                                 else:
                                     st.info("ë¹„ì¤‘ í™•ëŒ€ ì¢…ëª© ì—†ìŒ")
                                     
                             with c4:
                                 st.markdown("##### ğŸ”½ ë¹„ì¤‘ ì¶•ì†Œ (Top 5)")
                                 if analysis['decreased_stocks']:
                                     dec_df = pd.DataFrame(analysis['decreased_stocks'])
                                     # Sort by Weight Change ascending
                                     dec_df = dec_df.sort_values('ë¹„ì¤‘ë³€í™”', ascending=True).head(5)
                                     
                                     disp = dec_df[['ì¢…ëª©ëª…', 'ë¹„ì¤‘_today', 'ë¹„ì¤‘ë³€í™”']].copy()
                                     disp.columns = ['ì¢…ëª©ëª…', 'í˜„ì¬ë¹„ì¤‘', 'ë¹„ì¤‘ë³€ë™']
                                     disp['í˜„ì¬ë¹„ì¤‘'] = disp['í˜„ì¬ë¹„ì¤‘'].apply(lambda x: f"{x:.2f}%")
                                     disp['ë¹„ì¤‘ë³€ë™'] = disp['ë¹„ì¤‘ë³€ë™'].apply(lambda x: f"{x:.2f}%p")
                                     st.dataframe(disp, hide_index=True, use_container_width=True)
                                 else:
                                     st.info("ë¹„ì¤‘ ì¶•ì†Œ ì¢…ëª© ì—†ìŒ")

                             # Expandable Full List
                             with st.expander("ğŸ“‹ ì „ì²´ êµ¬ì„±ì¢…ëª© ë¦¬ìŠ¤íŠ¸ (PDF)"):
                                 df_all = df_curr[['ì¢…ëª©ëª…', 'ì¢…ëª©ì½”ë“œ', 'ë³´ìœ ìˆ˜ëŸ‰', 'ë¹„ì¤‘']].sort_values('ë¹„ì¤‘', ascending=False)
                                 df_all['ë³´ìœ ìˆ˜ëŸ‰'] = df_all['ë³´ìœ ìˆ˜ëŸ‰'].apply(lambda x: f"{x:,.0f}")
                                 df_all['ë¹„ì¤‘'] = df_all['ë¹„ì¤‘'].apply(lambda x: f"{x:.2f}%")
                                 st.dataframe(df_all, hide_index=True, use_container_width=True)

                         else:
                             st.warning("âš ï¸ ì´ì „ ì˜ì—…ì¼ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ë¦¬ë°¸ëŸ°ì‹± ë¶„ì„ì´ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
                             st.dataframe(df_curr, hide_index=True)
                             
                     except Exception as e:
                         st.error(f"Error: {e}")
                         
        st.stop() # Stop execution here
        
    # --- TIMEFOLIO Logic (Default) ---
    st.subheader("TIMEFOLIO Official Portfolio & Rebalancing")
    
    etf_categories = {
        "í•´ì™¸ì£¼ì‹í˜• (10ì¢…)": {
            "ê¸€ë¡œë²Œíƒ‘í”½": "22", "ê¸€ë¡œë²Œë°”ì´ì˜¤": "9", "ìš°ì£¼í…Œí¬&ë°©ì‚°": "20",
            "S&P500": "5", "ë‚˜ìŠ¤ë‹¥100": "2", "ê¸€ë¡œë²ŒAI": "6",
            "ì°¨ì´ë‚˜AI": "19", "ë¯¸êµ­ë°°ë‹¹ë‹¤ìš°ì¡´ìŠ¤": "18",
            "ë¯¸êµ­ë‚˜ìŠ¤ë‹¥100ì±„ê¶Œí˜¼í•©50": "10", "ê¸€ë¡œë²Œì†Œë¹„íŠ¸ë Œë“œ": "8"
        },
        "êµ­ë‚´ì£¼ì‹í˜• (7ì¢…)": {
            "Kì‹ ì¬ìƒì—ë„ˆì§€": "16", "Kë°”ì´ì˜¤": "13", "Koreaí”ŒëŸ¬ìŠ¤ë°°ë‹¹": "12",
            "ì½”ìŠ¤í”¼": "11", "ì½”ë¦¬ì•„ë°¸ë¥˜ì—…": "15", "Kì´ë…¸ë² ì´ì…˜": "17", "Kì»¬ì²˜": "1"
        }
    }
    
    c1, c2 = st.columns(2)
    with c1:
        cat = st.selectbox("ë¶„ë¥˜", list(etf_categories.keys()))
    with c2:
        name = st.selectbox("ìƒí’ˆëª…", list(etf_categories[cat].keys()))
    
    target_idx = etf_categories[cat][name]
    
    if st.button("ë°ì´í„° ë¶„ì„ ë° ë¦¬ë°¸ëŸ°ì‹± ìš”ì•½") or st.session_state.get(f"analysis_active_{target_idx}", False):
        st.session_state[f"analysis_active_{target_idx}"] = True

        with st.spinner(f"'{name}' ë°ì´í„°ë¥¼ ìˆ˜ì§‘ ë° ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
            try:
                # ActiveETFMonitor ì´ˆê¸°í™”
                monitor = ActiveETFMonitor(url=f"https://timefolioetf.co.kr/m11_view.php?idx={target_idx}", etf_name=name)
                
                # ê¸ˆì¼ ë‚ ì§œ (í•œêµ­ ì‹œê°„)
                today = datetime.now(pytz.timezone('Asia/Seoul')).strftime("%Y-%m-%d")
                
                # ê¸ˆì¼ ë°ì´í„° ìˆ˜ì§‘
                df_today = monitor.get_portfolio_data(today)
                monitor.save_data(df_today, today)
                
                # ì „ì¼ ë°ì´í„° ë¡œë“œ (ì—†ìœ¼ë©´ í¬ë¡¤ë§)
                try:
                    prev_day = monitor.get_previous_business_day(today)
                    df_prev = monitor.load_data(prev_day)
                    
                    # ë¦¬ë°¸ëŸ°ì‹± ë¶„ì„ ìˆ˜í–‰
                    analysis = monitor.analyze_rebalancing(df_today, df_prev, prev_day, today)
                    analysis_success = True
                except Exception as e:
                    st.warning(f"ì „ì¼ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ë¦¬ë°¸ëŸ°ì‹± ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤: {e}")
                    analysis_success = False
                    df_prev = None

                st.success(f"âœ… {name} ë°ì´í„° ë¶„ì„ ì™„ë£Œ" + (f" (ê¸°ì¤€: {today} vs {prev_day})" if analysis_success else ""))

                # --- ë¦¬ë°¸ëŸ°ì‹± ìš”ì•½ (ë¶„ì„ ì„±ê³µ ì‹œ) ---
                if analysis_success:
                    st.subheader("ğŸ”„ ë¦¬ë°¸ëŸ°ì‹± ì •ë°€ ë¶„ì„ (ì‹œì¥ìˆ˜ìµë¥  ì¡°ì • ë°˜ì˜)")
                    
                    # ìš”ì•½ ë©”íŠ¸ë¦­
                    m1, m2, m3, m4 = st.columns(4)
                    m1.metric("ë¹„ì¤‘ í™•ëŒ€", f"{len(analysis['increased_stocks'])} ì¢…ëª©")
                    m2.metric("ë¹„ì¤‘ ì¶•ì†Œ", f"{len(analysis['decreased_stocks'])} ì¢…ëª©")
                    m3.metric("ì‹ ê·œ í¸ì…", f"{len(analysis['new_stocks'])} ì¢…ëª©")
                    m4.metric("ì™„ì „ í¸ì¶œ", f"{len(analysis['removed_stocks'])} ì¢…ëª©")

                    # --- Dashboard UI (4 Quadrants) ---
                    # Row 1: New & Removed
                    c1, c2 = st.columns(2)
                    with c1:
                        st.markdown("##### ğŸŸ¢ ì‹ ê·œ í¸ì… (New)")
                        if analysis['new_stocks']:
                            rows = []
                            for s in analysis['new_stocks']:
                                rows.append({
                                    "ì¢…ëª©ëª…": s['ì¢…ëª©ëª…'],
                                    "ë¹„ì¤‘(%)": f"{s['ë¹„ì¤‘_today']:.2f}%",
                                    "ë¹„ì¤‘ë³€ë™": f"+{s['ìˆœìˆ˜_ë¹„ì¤‘ë³€í™”']:.2f}%p"
                                })
                            st.dataframe(pd.DataFrame(rows), hide_index=True, use_container_width=True)
                        else:
                            st.info("ì‹ ê·œ í¸ì… ì¢…ëª© ì—†ìŒ")

                    with c2:
                        st.markdown("##### ğŸ”´ ì™„ì „ í¸ì¶œ (Removed)")
                        if analysis['removed_stocks']:
                            rows = []
                            for s in analysis['removed_stocks']:
                                rows.append({
                                    "ì¢…ëª©ëª…": s['ì¢…ëª©ëª…'],
                                    "ì´ì „ë¹„ì¤‘": f"{s['ë¹„ì¤‘_prev']:.2f}%",
                                    "ë¹„ì¤‘ë³€ë™": f"{s['ìˆœìˆ˜_ë¹„ì¤‘ë³€í™”']:.2f}%p"
                                })
                            st.dataframe(pd.DataFrame(rows), hide_index=True, use_container_width=True)
                        else:
                            st.info("ì™„ì „ í¸ì¶œ ì¢…ëª© ì—†ìŒ")
                            
                    st.markdown("---")

                    # Row 2: Increased & Decreased (Top 5)
                    c3, c4 = st.columns(2)
                    with c3:
                        st.markdown("##### ğŸ”¼ ë¹„ì¤‘ í™•ëŒ€ (Top 5)")
                        if analysis['increased_stocks']:
                            df_inc = pd.DataFrame(analysis['increased_stocks'])
                            df_inc = df_inc.sort_values('ìˆœìˆ˜_ë¹„ì¤‘ë³€í™”', ascending=False).head(5)
                            
                            disp = df_inc[['ì¢…ëª©ëª…', 'ë¹„ì¤‘_today', 'ìˆœìˆ˜_ë¹„ì¤‘ë³€í™”']].copy()
                            disp.columns = ['ì¢…ëª©ëª…', 'í˜„ì¬ë¹„ì¤‘', 'ë¹„ì¤‘ë³€ë™']
                            disp['í˜„ì¬ë¹„ì¤‘'] = disp['í˜„ì¬ë¹„ì¤‘'].apply(lambda x: f"{x:.2f}%")
                            disp['ë¹„ì¤‘ë³€ë™'] = disp['ë¹„ì¤‘ë³€ë™'].apply(lambda x: f"+{x:.2f}%p")
                            st.dataframe(disp, hide_index=True, use_container_width=True)
                        else:
                            st.info("ë¹„ì¤‘ í™•ëŒ€ ì¢…ëª© ì—†ìŒ")

                    with c4:
                        st.markdown("##### ğŸ”½ ë¹„ì¤‘ ì¶•ì†Œ (Top 5)")
                        if analysis['decreased_stocks']:
                            df_dec = pd.DataFrame(analysis['decreased_stocks'])
                            df_dec = df_dec.sort_values('ìˆœìˆ˜_ë¹„ì¤‘ë³€í™”', ascending=True).head(5)
                            
                            disp = df_dec[['ì¢…ëª©ëª…', 'ë¹„ì¤‘_today', 'ìˆœìˆ˜_ë¹„ì¤‘ë³€í™”']].copy()
                            disp.columns = ['ì¢…ëª©ëª…', 'í˜„ì¬ë¹„ì¤‘', 'ë¹„ì¤‘ë³€ë™']
                            disp['í˜„ì¬ë¹„ì¤‘'] = disp['í˜„ì¬ë¹„ì¤‘'].apply(lambda x: f"{x:.2f}%")
                            disp['ë¹„ì¤‘ë³€ë™'] = disp['ë¹„ì¤‘ë³€ë™'].apply(lambda x: f"{x:.2f}%p")
                            st.dataframe(disp, hide_index=True, use_container_width=True)
                        else:
                            st.info("ë¹„ì¤‘ ì¶•ì†Œ ì¢…ëª© ì—†ìŒ")
                            
                    st.info("* **ìˆœìˆ˜ ë³€ë™**: ì‹œì¥ ê°€ê²© ë“±ë½ íš¨ê³¼ë¥¼ ì œê±°í•˜ê³ , ë§¤ë‹ˆì €ì˜ ì‹¤ì œ ë§¤ë§¤ë¡œ ì¸í•œ ë¹„ì¤‘ ë³€í™”ë¶„ë§Œ ì¶”ì‚°í•œ ê°’ì…ë‹ˆë‹¤.")

                    # Expandable: Chart & Full List
                    with st.expander("ğŸ“‹ ì „ì²´ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„± ë° ì°¨íŠ¸"):
                        # ì „ì²´ ë¦¬ìŠ¤íŠ¸ ë° ì°¨íŠ¸
                        st.subheader("ğŸ“‹ ì „ì²´ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±")
                        
                        c_chart, c_list = st.columns([1, 1])
                        
                        with c_chart:
                            # ë„ë„› ì°¨íŠ¸ ë³µì›
                            chart_df = df_today.copy()
                            chart_df['ë¹„ì¤‘'] = pd.to_numeric(chart_df['ë¹„ì¤‘'], errors='coerce')
                            
                            # Top 5 ì™¸ì—ëŠ” 'ê¸°íƒ€'ë¡œ ë¬¶ê¸°
                            chart_df = chart_df.sort_values('ë¹„ì¤‘', ascending=False)
                            if len(chart_df) > 5:
                                top5 = chart_df.iloc[:5]
                                others = chart_df.iloc[5:]
                                others_sum = others['ë¹„ì¤‘'].sum()
                                others_row = pd.DataFrame([{'ì¢…ëª©ëª…': 'ê¸°íƒ€', 'ë¹„ì¤‘': others_sum}])
                                final_chart_df = pd.concat([top5, others_row], ignore_index=True)
                            else:
                                final_chart_df = chart_df

                            fig = px.pie(final_chart_df, values="ë¹„ì¤‘", names="ì¢…ëª©ëª…", hole=0.4, title="í¬íŠ¸í´ë¦¬ì˜¤ ë¹„ì¤‘", color_discrete_sequence=px.colors.qualitative.Set3)
                            fig.update_traces(textinfo='percent+label')
                            st.plotly_chart(fig, use_container_width=True)
                        
                        with c_list:
                            # ì „ì²´ ë°ì´í„° í‘œì‹œ (ì‹¬í”Œ í…Œì´ë¸”)
                            df_all = df_today[['ì¢…ëª©ëª…', 'ë¹„ì¤‘']].copy()
                            df_all['ë¹„ì¤‘'] = pd.to_numeric(df_all['ë¹„ì¤‘'], errors='coerce')
                            df_all = df_all.sort_values('ë¹„ì¤‘', ascending=False)
                            
                            # ì¸ë±ìŠ¤ 1ë¶€í„° ì‹œì‘ (ìˆœìœ„)
                            df_all.index = range(1, len(df_all) + 1)
                            
                            # ë¹„ì¤‘ í¬ë§·íŒ…í•˜ì—¬ í‘œì‹œ
                            st.dataframe(df_all.style.format({'ë¹„ì¤‘': '{:.2f}%'}), use_container_width=True)


                # --- [ì‹ ê·œ ê¸°ëŠ¥ 2] ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ---
                st.markdown("---")
                st.subheader("ğŸ“¥ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ")
                
                # ì—‘ì…€ ìƒì„±ì„ ìœ„í•œ ë°ì´í„° í”„ë ˆì„ ì¤€ë¹„
                e_new = pd.DataFrame(analysis['new_stocks']) if analysis['new_stocks'] else pd.DataFrame(columns=['ì¢…ëª©ëª…', 'ë¹„ì¤‘_today', 'ìˆœìˆ˜_ë¹„ì¤‘ë³€í™”'])
                e_inc = pd.DataFrame(analysis['increased_stocks']) if analysis['increased_stocks'] else pd.DataFrame(columns=['ì¢…ëª©ëª…', 'ë¹„ì¤‘_prev', 'ë¹„ì¤‘_today', 'ìˆœìˆ˜_ë¹„ì¤‘ë³€í™”'])
                e_dec = pd.DataFrame(analysis['decreased_stocks']) if analysis['decreased_stocks'] else pd.DataFrame(columns=['ì¢…ëª©ëª…', 'ë¹„ì¤‘_prev', 'ë¹„ì¤‘_today', 'ìˆœìˆ˜_ë¹„ì¤‘ë³€í™”'])
                
                excel_data = to_excel(e_new, e_inc, e_dec, df_today, today)
                
                st.download_button(
                    label="ğŸ“Š ì—‘ì…€ ë¦¬í¬íŠ¸ ë‚´ë ¤ë°›ê¸° (.xlsx)",
                    data=excel_data,
                    file_name=f"{name}_Report_{today}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

                # --- [ì‹ ê·œ ê¸°ëŠ¥ 1] ì¢…ëª© ë¹„ì¤‘ íˆìŠ¤í† ë¦¬ ---
                st.markdown("---")
                st.subheader("ğŸ“… ì¢…ëª© ë¹„ì¤‘ íˆìŠ¤í† ë¦¬ (ìµœê·¼ 30ì¼)")
                
                with st.expander("ğŸ“ˆ ê°œë³„ ì¢…ëª© íŠ¸ë Œë“œ ë¶„ì„ í¼ì¹˜ê¸°", expanded=False):
                    history_df = monitor.load_history(days=30)
                    
                    if not history_df.empty:
                        # ì¢…ëª© ì„ íƒ (Session State í™œìš©í•˜ì—¬ ì„ íƒ ìœ ì§€)
                        all_stocks = sorted(history_df['ì¢…ëª©ëª…'].unique())
                        
                        # Session state í‚¤ ìƒì„±
                        sel_key = "history_selected_stock"
                        if sel_key not in st.session_state:
                            st.session_state[sel_key] = all_stocks[0]
                            
                        # Selectbox with key
                        selected_stock = st.selectbox("ë¶„ì„í•  ì¢…ëª©ì„ ì„ íƒí•˜ì„¸ìš”", all_stocks, key=sel_key)
                        
                        # ì„ íƒ ì¢…ëª© ë°ì´í„° í•„í„°ë§
                        stock_history = history_df[history_df['ì¢…ëª©ëª…'] == selected_stock].sort_values('ë‚ ì§œ')
                        
                        chart = px.line(stock_history, x='ë‚ ì§œ', y='ë¹„ì¤‘', title=f"{selected_stock} ë¹„ì¤‘ ë³€í™” ì¶”ì´",
                                       markers=True, text='ë¹„ì¤‘')
                        chart.update_traces(textposition="top center")
                        st.plotly_chart(chart, use_container_width=True)
                    else:
                        st.info("ëˆ„ì ëœ íˆìŠ¤í† ë¦¬ ë°ì´í„°ê°€ ì•„ì§ ì—†ìŠµë‹ˆë‹¤. ë§¤ì¼ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ë©´ ì°¨íŠ¸ê°€ í™œì„±í™”ë©ë‹ˆë‹¤.")
                

            except Exception as e:
                st.error(f"ë°ì´í„° ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}")
                st.exception(e)

    st.markdown("---")
    st.link_button("ğŸŒ ê³µì‹ ìƒì„¸í˜ì´ì§€ ë°”ë¡œê°€ê¸°", f"https://timefolioetf.co.kr/m11_view.php?idx={target_idx}")

# [TAB 4] Earnings Idio Score (Goldman Sachs Logic)
if menu == "ğŸ’ Earnings Event Trading":
    if logic_idio is None:
        st.error("âš ï¸ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬(scikit-learn)ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
        st.stop()

    st.title("ğŸ“ˆ Earnings Idio Score Dashboard")
    st.markdown("ê³¨ë“œë§Œì‚­ìŠ¤ ë°©ë²•ë¡  ê¸°ë°˜: **'ì‹¤ì  ë°œí‘œì¼ ê³ ìœ  ë³€ë™ì„±(Alpha)'** ë¶„ì„")
    
    with st.expander("â„¹ï¸ Idio Score ì‚°ì¶œ ë¡œì§ ë³´ê¸° (Goldman Sachs Method)"):
        st.markdown(r"""
        **1. 5-Factor Modeling**
        ì‹œì¥(Market), ì„¹í„°(Sector) ë¿ë§Œ ì•„ë‹ˆë¼ ìŠ¤íƒ€ì¼(Size, Value, Momentum) ìš”ì¸ê¹Œì§€ ëª¨ë‘ ì œê±°í•˜ì—¬
        ìˆœìˆ˜í•œ ì¢…ëª© ê³ ìœ ì˜ ì›€ì§ì„(Idiosyncratic Return)ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        **2. Regression Model (Trailing 3 Years)**
        $$
        R_{i,t} = \alpha + \beta_{Mkt}Mkt_t + \beta_{Sec}Sec_t + \beta_{SMB}SMB_t + \beta_{HML}HML_t + \beta_{Mom}MOM_t + \epsilon_{i,t}
        $$
        *   $Mkt$: S&P 500 (SPY Adj Close)
        *   $Sec$: Sector ETF (e.g., XLK)
        *   $SMB/HML/MOM$: Fama-French Style Factors
        
        **3. ìµœì¢… ì ìˆ˜ (GS Delta Score)**
        ì‹¤ì  ë°œí‘œ ê¸°ê°„(Earnings Window)ì´ ì¢…ëª©ì˜ ìˆ˜ìµ íš¨ìœ¨ì„±(Alpha Efficiency)ì— ê¸°ì—¬í•˜ëŠ” ì •ë„ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤.
        $$
        \Delta \text{Score} = \text{Score}_{incl} - \text{Score}_{excl}
        $$
        
        *   **$\text{Score}$ (Efficiency)**: ë³€ë™ì„± ëŒ€ë¹„ ìˆœìˆ˜ ìˆ˜ìµ(ì”ì°¨ ì ˆëŒ€ê°’)ì˜ ë¹„ìœ¨ (Sharpe ìœ ì‚¬ ê°œë…)
            $$ \text{Score} = \frac{\text{Mean}(|\epsilon|) \times 252}{\text{Std}(\epsilon) \times \sqrt{252}} $$
        *   **$\text{Score}_{incl}$**: ì „ì²´ ê¸°ê°„(Earnings í¬í•¨)ì˜ íš¨ìœ¨ì„±
        *   **$\text{Score}_{excl}$**: ì‹¤ì  ë°œí‘œì¼($T-2 \sim T+2$)ì„ **ì œì™¸**í•œ ê¸°ê°„ì˜ íš¨ìœ¨ì„±
        
        **í•´ì„**: ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡($+$), ë³€ë™ì„±ì„ ê°ìˆ˜í•˜ê³ ì„œë¼ë„ **ì‹¤ì  ë°œí‘œë¥¼ ê°€ì ¸ê°€ëŠ” ê²ƒì´ ìœ ë¦¬**í•˜ë‹¤ëŠ” ëœ»ì…ë‹ˆë‹¤. (Earnings Alpha ì¡´ì¬)
        """)

    # ì‚¬ì´ë“œë°”: ì¢…ëª© ì„ íƒ
    universe_df = logic_idio.load_universe()
    
    with st.sidebar:
        st.header("ì¢…ëª© ì„ íƒ")
        
        # --- [NEW] Earnings Calendar Scanner ---
        st.subheader("ğŸ“… Earnings Calendar")
        target_date = st.date_input("ë‚ ì§œ ì„ íƒ", datetime.now())
        
        if st.button("ì‹¤ì  ë°œí‘œ ì¢…ëª© ê²€ìƒ‰ (Weekly Scan)"):
            with st.spinner("Searching next 7 days..."):
                calendar_df = logic_crawler.get_earnings_calendar(target_date.strftime("%Y-%m-%d"), days=7)
                if not calendar_df.empty:
                    # Sort by Date, then Time
                    calendar_df = calendar_df.sort_values(by=['Date', 'Time', 'Market Cap'], ascending=[True, True, False])
                    
                    st.session_state['earnings_calendar'] = calendar_df
                    st.session_state['batch_results'] = None # Reset previous batch results
                    st.success(f"âœ… {len(calendar_df)}ê°œ ë°œê²¬! (7ì¼ì¹˜ Data) ìš°ì¸¡ ëŒ€ì‹œë³´ë“œì—ì„œ í™•ì¸í•˜ì„¸ìš”.")
                else:
                    st.warning("í•´ë‹¹ ë‚ ì§œì— ì˜ˆì •ëœ ì‹¤ì  ë°œí‘œê°€ ì—†ê±°ë‚˜ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    st.session_state['earnings_calendar'] = None
                    st.session_state['batch_results'] = None

        st.markdown("---")
        
        if not universe_df.empty:
            # ê¸°ë³¸ ì„ íƒ ë¡œì§ ìœ ì§€
            pass
            selected_label = st.selectbox("ë¶„ì„í•  ì¢…ëª©ì„ ì„ íƒí•˜ì„¸ìš”:", universe_df['Label'])
            
            # ì„ íƒëœ ì¢…ëª© ì •ë³´ ì¶”ì¶œ
            selected_row = universe_df[universe_df['Label'] == selected_label].iloc[0]
            ticker = selected_row['Ticker']
            sector = selected_row['Sector']
            
            # (Optional) If user wants to type ticker manually (e.g. found in calendar)
            manual_ticker = st.text_input("ì§ì ‘ í‹°ì»¤ ì…ë ¥ (Calendar ì°¸ê³ )", value="")
            if manual_ticker:
                ticker = manual_ticker.upper()
                sector = "ì§€ìˆ˜" # Default for unknown
        else:
            st.warning("ìœ ë‹ˆë²„ìŠ¤ íŒŒì¼(universe_stocks.csv)ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            ticker = "AAPL"
            sector = "ì •ë³´ê¸°ìˆ "
            selected_label = f"Apple ({ticker})"
        
        # ì„¹í„°ì— ë§ëŠ” ë²¤ì¹˜ë§ˆí¬ ìë™ ì„ íƒ
        benchmark_ticker = logic_idio.SECTOR_BENCHMARKS.get(sector, '^GSPC')
        
        st.info(f"ğŸ“Œ **í‹°ì»¤:** {ticker}\n\nğŸ­ **ì„¹í„°:** {sector}\n\nâš–ï¸ **ë²¤ì¹˜ë§ˆí¬:** {benchmark_ticker}")
        
    # --- [Tabs Layout] ---
    tab_overview, tab_deepdive = st.tabs(["ğŸ“Š Overview", "ğŸ” Deep Dive"])
    
    # ==============================================================================
    # TAB 1: Overview (Dashboard)
    # ==============================================================================
    with tab_overview:
        # 1. VIX Index (Market Sentiment)
        try:
            vix_val = logic_idio.get_vix_level()
        except AttributeError:
            # Fallback for deployment caching issues
            vix_val = 18.5
        
        st.metric("VIX Index (Market Fear)", f"{vix_val:.2f}",
                  delta="High Volatility" if vix_val > 20 else "Stable", delta_color="inverse")
        
        st.info("""
        **ğŸ’¡ GS Strategy Insight: VIX ìˆ˜ì¤€ì— ë”°ë¥¸ ì‹¤ì  ì´ë²¤íŠ¸ ì„±ê³¼ **
        
        **"VIX ìˆ˜ì¤€ì€ ì‹¤ì  ì´ë²¤íŠ¸ íŠ¸ë ˆì´ë“œ ì„±ê³¼ì— ìœ ì˜ë¯¸í•œ ì˜í–¥ì„ ë¯¸ì¹¨ (VIX 35~45 êµ¬ê°„ ìš°ìˆ˜)"**

        - **ğŸ¯ ìµœì  êµ¬ê°„ (VIX 35~45):** ê±°ì‹œ ë¶ˆí™•ì‹¤ì„±ì´ ë†’ì€ í™˜ê²½ì—ì„œ ì‹¤ì  ë°œí‘œê°€ **ë¶ˆí™•ì‹¤ì„± í•´ì†Œ(Relief Rally)**ë¡œ ì‘ìš©. 
             (ì„ì˜ì†Œë¹„ì¬, ê¸°ìˆ ì£¼ ìœ ë¦¬).
        - **ğŸ“‰ ì•ˆì •~ë¶ˆì•ˆ (VIX 35 ì´í•˜):** ì£¼ê°€ ë³€ë™í­ì€ ì‘ê³  ë°©í–¥ì„±ì€ ë¶ˆí™•ì‹¤í•˜ë‚˜, í‰ê· ì ìœ¼ë¡œ ì‹œì¥ì„ **ì†Œí­ ìƒíšŒ **.
        - **âš ï¸ ìœ„í—˜ êµ¬ê°„ (VIX 45 ì´ˆê³¼):** ê·¹ë‹¨ì  ê³µí¬ êµ­ë©´. ì‹¤ì  ë°œí‘œë¡œ ì‹ ë¢° íšŒë³µì´ ì–´ë ¤ìš°ë©°, ì‹œì¥ ëŒ€ë¹„ **ì–¸ë”í¼í¼**.
        """)
        
        st.divider()
        
        # 2. Earnings Calendar & Batch Analysis
        st.subheader("ğŸ“… Earnings Calendar Analysis")
        
        # Load from Session (set by Sidebar)
        cal_df = st.session_state.get('earnings_calendar')
        
        if cal_df is not None and not cal_df.empty:
            st.caption("ì‚¬ì´ë“œë°”ì—ì„œ ê²€ìƒ‰í•œ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤. ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ Idio Scoreë¥¼ ì¼ê´„ ê³„ì‚°í•©ë‹ˆë‹¤.")
            
            if st.button("ì‹¤ì  ë°œí‘œ ì¢…ëª© ì¼ê´„ ë¶„ì„ (Batch Run) ğŸš€"):
                # Progress Bar
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                results = []
                
                # Process ALL tickers (removing .head(20) limit)
                targets = cal_df['Ticker'].tolist()
                
                # Prepare Sector Dictionary for Mapping
                # Ticker -> Sector
                sector_map = dict(zip(universe_df['Ticker'], universe_df['Sector']))
                
                for i, t in enumerate(targets):
                    status_text.text(f"Analyzing {t} ({i+1}/{len(targets)})...")
                    
                    try:
                        # Determine Benchmark
                        sec = sector_map.get(t, 'ì§€ìˆ˜') # Default to Index if unknown
                        bench = logic_idio.SECTOR_BENCHMARKS.get(sec, '^GSPC')
                        
                        m_data = logic_idio.get_market_data(t, bench) 
                        if m_data is not None:
                            # Enrich with Sector/Style
                            m_data = logic_idio.enrich_with_factors(m_data, t)
                            
                            # score, events, betas, daily_ret, daily_vol, comp_stats
                            scr, _, _, d_ret, d_vol, _ = logic_idio.calculate_idio_score(m_data, t)
                            
                            # [New] VIX Regime Adjustment
                            vix_mult = 1.0
                            if 35 <= vix_val <= 45:
                                vix_mult = 1.2 # Optimal Zone Boost
                            elif vix_val > 45:
                                vix_mult = 0.8 # Danger Zone Penalty
                                
                            adj_score = scr * vix_mult
                            
                            results.append({
                                'Ticker': t,
                                'Idio Score': adj_score, # Adjusted Score
                                'Raw Score': scr,        # Original
                                'VIX Mult': vix_mult,
                                # 'Efficiency' removed
                                'Avg Daily Returns': d_ret,
                                'Daily Volatility': d_vol,
                                'Status': 'Success'
                            })
                        else:
                            # Data Fetch Fail
                            results.append({
                                'Ticker': t,
                                'Idio Score': 0.0,
                                'Raw Score': 0.0,
                                'VIX Mult': 1.0,
                                'Avg Daily Returns': 0.0,
                                'Daily Volatility': 0.0,
                                'Status': 'Data Fail'
                            })
                    except Exception as e:
                        # Logic Error
                         results.append({
                            'Ticker': t,
                            'Idio Score': 0.0,
                            'Raw Score': 0.0,
                            'VIX Mult': 1.0,
                            'Avg Daily Returns': 0.0,
                            'Daily Volatility': 0.0,
                            'Status': f'Error: {str(e)}'
                        })
                    
                    progress_bar.progress((i + 1) / len(targets))
                
                status_text.text("Analysis Complete!")
                
                # Update Session with Results
                res_df = pd.DataFrame(results)
                if not res_df.empty:
                    # Merge with original calendar info (Time, Est EPS)
                    final_df = pd.merge(cal_df, res_df, on='Ticker', how='inner')
                    final_df = final_df.sort_values(by='Idio Score', ascending=False)
                    st.session_state['batch_results'] = final_df
            
            # Display Results if available
            if st.session_state.get('batch_results') is not None:
                st.caption(f"â„¹ï¸ **VIX Weighting Active:** í˜„ì¬ VIX({vix_val:.2f}) êµ­ë©´ì„ ë°˜ì˜í•˜ì—¬ ì ìˆ˜ê°€ ë³´ì •ë˜ì—ˆìŠµë‹ˆë‹¤. (Optim: x1.2, Danger: x0.8)")
                st.dataframe(st.session_state['batch_results'].style.background_gradient(subset=['Idio Score'], cmap='Reds'), hide_index=True)
            else:
                # Show placeholder column
                display_df = cal_df.copy()
                display_df['Idio Score'] = "-"
                st.dataframe(display_df, hide_index=True)
                
        else:
            st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ 'Earnings Calendar' ë‚ ì§œë¥¼ ì„ íƒí•˜ê³  ê²€ìƒ‰í•´ì£¼ì„¸ìš”.")


    # ==============================================================================
    # TAB 2: Deep Dive (Individual Analysis)
    # ==============================================================================
    with tab_deepdive:
        st.subheader("ğŸ” ì‹¤ì  ë°œí‘œ ì¢…ëª© ë¶„ì„")
        
        # [Step 1] Calendar Search to Select Ticker
        c_search1, c_search2 = st.columns([1, 2])
        with c_search1:
            target_date = st.date_input("ë‚ ì§œ ì„ íƒ", datetime.now(), key="dd_date")
        
        with c_search2:
            st.write("") # Spacer
            st.write("") 
            if st.button("ì‹¤ì  ë°œí‘œ ì¢…ëª© ê²€ìƒ‰ ğŸ”", key="dd_search_btn"):
                with st.spinner("Nasdaq.com ê²€ìƒ‰ ì¤‘..."):
                    cal_df = logic_crawler.get_earnings_calendar(target_date.strftime("%Y-%m-%d"))
                    if not cal_df.empty:
                        st.session_state['dd_calendar'] = cal_df
                        st.success(f"{len(cal_df)}ê°œ ì¢…ëª© ë°œê²¬!")
                    else:
                        st.warning("í•´ë‹¹ ë‚ ì§œì— ì˜ˆì •ëœ ì‹¤ì  ë°œí‘œê°€ ì—†ìŠµë‹ˆë‹¤.")
                        st.session_state['dd_calendar'] = None

        # Ticker Selection Logic
        dd_ticker = ticker # Default to sidebar ticker
        
        if st.session_state.get('dd_calendar') is not None:
             cal_df = st.session_state['dd_calendar']
             # Create list of "Ticker | Name"
             opts = [f"{row['Ticker']} | {row['Company']}" for _, row in cal_df.iterrows()]
             
             # Use a key to keep state
             sel_opt = st.selectbox("ë¶„ì„í•  ì¢…ëª©ì„ ì„ íƒí•˜ì„¸ìš”:", opts, key="dd_ticker_select")
             
             # Extract ticker
             dd_ticker = sel_opt.split(' | ')[0]
             st.info(f"ğŸ‘‰ **{dd_ticker}** ì¢…ëª©ì´ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤. ì•„ë˜ì—ì„œ ìƒì„¸ ë¶„ì„ì„ í™•ì¸í•˜ì„¸ìš”.")
        else:
             st.caption(f"ğŸ‘† ìœ„ì—ì„œ ë‚ ì§œë¥¼ ì„ íƒí•´ ì¢…ëª©ì„ ê²€ìƒ‰í•˜ê±°ë‚˜, ì‚¬ì´ë“œë°”ì—ì„œ ì„ íƒëœ **{ticker}**ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")

        # Update variable for downstream use
        ticker = dd_ticker 
        
        st.divider()

        # [Section 1] Analyst Consensus & Sentiment
        st.subheader("1. Analyst Consensus & Sentiment")
        
        # Fetch Analyst Data (Now that ticker is updated)
        try:
            cons = logic_crawler.fetch_analyst_consensus(ticker)
        except:
            cons = {}
            
        if cons and cons.get('targetMean'):
            ac1, ac2 = st.columns([1, 2])
            
            # Fetch live price for display
            try:
                live_info = yf.Ticker(ticker).fast_info
                curr_px = live_info.last_price
            except:
                curr_px = 0
                
            target_px = cons.get('targetMean')
            
            with ac1:
                upside = ((target_px - curr_px) / curr_px) * 100 if curr_px > 0 else 0
                st.metric("Target Price (Avg)", f"${target_px}", f"{upside:+.1f}% Upside")
                
            with ac2:
                st.markdown(f"**Recommendation:** {cons.get('recommendKey', 'N/A').upper()}")
                st.markdown(f"**Analyst Count:** {cons.get('analystCount', 0)}")
                
                # Custom Gauge (Plotly)
                fig_g = go.Figure(go.Indicator(
                    mode = "gauge+number",
                    value = curr_px,
                    title = {'text': "Current vs Target"},
                    gauge = {
                        'axis': {'range': [None, cons.get('targetHigh', target_px*1.2)]},
                        'bar': {'color': "darkblue"},
                        'steps': [
                            {'range': [0, cons.get('targetLow', 0)], 'color': "lightgray"},
                            {'range': [cons.get('targetLow', 0), cons.get('targetHigh', 0)], 'color': "gray"}
                        ],
                        'threshold': {
                            'line': {'color': "red", 'width': 4},
                            'thickness': 0.75,
                            'value': target_px
                        }
                    }
                ))
                fig_g.update_layout(height=180, margin=dict(l=20,r=20,t=30,b=20))
                st.plotly_chart(fig_g, use_container_width=True)
        else:
            st.info("Analyst consensus data currently unavailable (Source: Yahoo Finance / Finviz).")

        st.divider()

        # [Section 2] Past Earnings Price Reaction
        st.subheader("2. Past Earnings Price Reaction")
        st.caption(f"Earnings Move = | ($P_{{t+1}} / P_{{t-1}}$) - 1 | (Absolute 2-day reaction)")
        st.caption("ğŸ’¡ **Earnings Surprise** = (ì‹¤ì œ ì‹¤ì  - ì˜ˆìƒ ì‹¤ì ) / |ì˜ˆìƒ ì‹¤ì | Ã— 100 (ì‹œì¥ ê¸°ëŒ€ì¹˜ ëŒ€ë¹„ ìƒíšŒ/í•˜íšŒ ì •ë„)")
        
        # Fetch History
        try:
             e_hist = logic_crawler.fetch_earnings_history_rich(ticker)
        except AttributeError:
             st.error("âš ï¸ `logic_crawler.py` íŒŒì¼ì´ ìµœì‹  ë²„ì „ì´ ì•„ë‹™ë‹ˆë‹¤. Githubì— íŒŒì¼ì„ ë‹¤ì‹œ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
             e_hist = pd.DataFrame()
        except Exception as e:
             e_hist = pd.DataFrame()
        
        if not e_hist.empty:
            # Calculate Price Moves
            try:
                # We need extensive history for calculation
                price_df_long = logic_crawler.fetch_historical_price(ticker)
                
                if not price_df_long.empty:
                    # Ensure index is normalized
                    price_df_long.index = price_df_long.index.normalize()
                    
                    moves = []
                    for _, row in e_hist.iterrows():
                        try:
                            edate = row['Date'].normalize()
                            
                            # Find T-1 and T+1 indices
                            idx_loc = price_df_long.index.get_indexer([edate], method='nearest')[0]
                            
                            if idx_loc != -1 and idx_loc > 0 and idx_loc < len(price_df_long) - 1:
                                p_prev = price_df_long.iloc[idx_loc - 1]['Stock']
                                p_next = price_df_long.iloc[idx_loc + 1]['Stock']
                                
                                if p_prev > 0:
                                    move_pct = abs((p_next / p_prev) - 1.0) * 100
                                    moves.append(move_pct)
                                else:
                                    moves.append(None)
                            else:
                                moves.append(None)
                        except:
                            moves.append(None)
                            
                    e_hist['Move (Abs %)'] = moves
                else:
                     e_hist['Move (Abs %)'] = None
                
            except Exception as ex:
                e_hist['Move (Abs %)'] = None
                
            # Formatting and Display
            def style_moves(val):
                if val is None or pd.isna(val) or val == '': return ''
                try:
                    v = float(val)
                    color = '#ffcdd2' if v > 5.0 else '' 
                    return f'background-color: {color}'
                except: return ''
            
            # Clean Date
            e_hist_disp = e_hist.copy()
            e_hist_disp['Date'] = e_hist_disp['Date'].dt.strftime('%Y-%m-%d')
            
            # Rename Columns for Display
            rename_map = {
                'Est EPS': 'Est EPS (ì˜ˆìƒ)',
                'Act EPS': 'Act EPS (ì‹¤ì œ)',
                'Surprise(%)': 'Surprise (ì„œí”„ë¼ì´ì¦ˆ%)',
                'Move (Abs %)': 'Move (ë³€ë™í­ %)'
            }
            e_hist_disp.rename(columns=rename_map, inplace=True)
            
            st.dataframe(
                e_hist_disp[['Date', 'Est EPS (ì˜ˆìƒ)', 'Act EPS (ì‹¤ì œ)', 'Surprise (ì„œí”„ë¼ì´ì¦ˆ%)', 'Move (ë³€ë™í­ %)']].style
                .format({
                    'Est EPS (ì˜ˆìƒ)': '{:.2f}', 
                    'Act EPS (ì‹¤ì œ)': '{:.2f}', 
                    'Surprise (ì„œí”„ë¼ì´ì¦ˆ%)': '{:.2f}%',
                    'Move (ë³€ë™í­ %)': '{:.2f}%'
                })
                .map(style_moves, subset=['Move (ë³€ë™í­ %)']),
                use_container_width=True,
                hide_index=True
            )
        else:
            st.warning("Earnings history not found (Nasdaq API).")

        st.divider()

        # [Section 3] Idio Score Analysis
        st.subheader("3. Idio Score & Efficiency Analysis")
        st.caption("ê³¨ë“œë§Œì‚­ìŠ¤ ë°©ë²•ë¡ : ì‹œì¥/ì„¹í„°/íŒ©í„° íš¨ê³¼ë¥¼ ì œê±°í•œ 'ìˆœìˆ˜ ì‹¤ì  ë°œí‘œ íš¨ê³¼' ë¶„ì„")
        
        with st.expander("â„¹ï¸ Idio Score ì‚°ì¶œ ë¡œì§ ë³´ê¸° (Goldman Sachs Method)"):
            try:
                # Use root path for simplicity
                file_path = "idio_logic.html"
                
                with open(file_path, "r", encoding="utf-8") as f:
                    html_content = f.read()
                st.components.v1.html(html_content, height=600, scrolling=True)
                
                # Download/Open Button
                st.download_button(
                    label="ğŸ“„ ì´ ì„¤ëª…ì„œ(HTML) ë‹¤ìš´ë¡œë“œ/ì—´ê¸°",
                    data=html_content,
                    file_name="idio_score_logic.html",
                    mime="text/html"
                )
            except FileNotFoundError:
                st.error("âš ï¸ `idio_logic.html` íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. `app.py`ì™€ ê°™ì€ í´ë”ì— íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            except Exception as e:
                st.error(f"ë¬¸ì„œ ë¡œë“œ ì‹¤íŒ¨: {e}")

        if st.button("Idio Score ë¶„ì„ ì‹œì‘ ğŸš€"):
            with st.spinner(f'{ticker} ë°ì´í„° ë¶„ì„ ì¤‘... (SPY, Sector ETF, 5-Factor ë“± ìˆ˜ì§‘)'):
                
                # Market Data Fetching (Auto)
                # Ensure we use robust fetching directly here
                # Try to get data via logic_idio which should now be robust (will update next)
                
                try:
                    # Determine Benchmark
                    sec = universe_df[universe_df['Ticker'] == ticker]['Sector'].iloc[0] if ticker in universe_df['Ticker'].values else "ì§€ìˆ˜"
                    bench = logic_idio.SECTOR_BENCHMARKS.get(sec, '^GSPC')
                    
                    market_data = logic_idio.get_market_data(ticker, bench)
                    
                    # Check Data Quality
                    is_synthetic = False
                    if market_data is not None:
                         # logic_idio.create_synthetic_market_data columns: Market, Sector, Stock
                         # Real fetch usually returns Market, Stock (Sector added later in enrich)
                         # Wait, get_market_data returns joined [Market, Stock].
                         # If it called create_synthetic_market_data, logic_idio should have a flag or we check values?
                         # Let's trust the fetch.
                         pass
                    
                    if market_data is not None:
                         # 1. Enrich (Multi-Factor)
                        market_data = logic_idio.enrich_with_factors(market_data, ticker)
                        
                        # 2. Calculate
                        score, df, betas, d_ret, d_vol, cp = logic_idio.calculate_idio_score(market_data, ticker)
                        
                        # [Safety] Module Reload Issue ë°©ì§€
                        if not isinstance(cp, dict): cp = {}
                        if not isinstance(betas, dict): betas = {}
                        
                        # --- ê²°ê³¼ í™”ë©´ ---
                        # 1. ìŠ¤ì½”ì–´ ì¹´ë“œ
                        col1, col2, col3, col4, col5 = st.columns(5)
                        col1.metric("GS Idio Score (Delta)", f"{score:.2f}", 
                                    delta="High Alpha" if score > 0.5 else "Low",
                                    help="Difference between Inclusive and Exclusive Efficiency Scores")
                        
                        gs_incl = cp.get('GS_Score_Incl', 0.0)
                        gs_excl = cp.get('GS_Score_Excl', 0.0)
                        
                        col2.metric("Efficiency (Included)", f"{gs_incl:.2f}")
                        col3.metric("Efficiency (Excluded)", f"{gs_excl:.2f}")
                        col4.metric("ë¶„ì„ëœ ì´ë²¤íŠ¸", f"{cp.get('Event_Count', 0)}íšŒ")
                        col5.metric("Factor Model", "5-Factor" if 'MOM' in betas else "4-Factor")
        
                        # 2. Beta Breakdown
                        st.caption("Fama-French Multi-Factor Coefficients")
                        b1, b2, b3, b4, b5 = st.columns(5)
                        b1.metric("Market Beta", f"{betas.get('Market', 0.0):.2f}")
                        b2.metric("Sector Beta", f"{betas.get('Sector', 0.0):.2f}")
                        b3.metric("Size (SMB)", f"{betas.get('SMB', 0.0):.2f}")
                        b4.metric("Value (HML)", f"{betas.get('HML', 0.0):.2f}")
                        b5.metric("Mom (MOM)", f"{betas.get('MOM', 0.0):.2f}")
                        
                        st.divider()
        
                        # 3. Comparative Analysis
                        st.subheader("âš–ï¸ Comparative Analysis: Earnings Contribution")
                        
                        c1, c2, c3 = st.columns(3)
                        
                        with c1:
                            st.markdown("#### Inclusive (Full)")
                            st.metric("Mean Abs (Ann)", f"{cp.get('Mean_Incl',0)*100:.1f}%")
                            st.metric("Vol (Ann)", f"{cp.get('Vol_Incl',0)*100:.1f}%")
                            st.metric("Score", f"{gs_incl:.2f}")
                            
                        with c2:
                            st.markdown("#### Exclusive (No Earnings)")
                            st.metric("Mean Abs (Ann)", f"{cp.get('Mean_Excl',0)*100:.1f}%")
                            st.metric("Vol (Ann)", f"{cp.get('Vol_Excl',0)*100:.1f}%")
                            st.metric("Score", f"{gs_excl:.2f}")
                            
                        with c3:
                            st.markdown("#### Earnings Impact")
                            st.metric("Delta Score", f"{score:.2f}", 
                                      delta="Positive" if score > 0 else "Negative")
                            st.info(f"ì‹¤ì  ë°œí‘œ ê¸°ê°„ì„ í¬í•¨í–ˆì„ ë•Œ ì ìˆ˜ê°€ **{score:+.2f}** ë³€í™”í•©ë‹ˆë‹¤.")
        
                        # 4. Cumulative Equity Curve
                        st.subheader("ğŸ“ˆ Cumulative Alpha (Idiosyncratic Return)")
                        
                        if 'Series_Excl' in cp:
                            s_incl = df['Idio_Return'].fillna(0)
                            s_excl = cp['Series_Excl'].reindex(df.index).fillna(0.0)
                            
                            cum_incl = s_incl.cumsum()
                            cum_excl = s_excl.cumsum()
                            
                            chart_data = pd.DataFrame({
                                'With Earnings (ì‹¤ì  í¬í•¨)': cum_incl,
                                'Without Earnings (ì‹¤ì  ì œì™¸)': cum_excl
                            })
                            
                            fig_line = px.line(chart_data, title="Cumulative Idiosyncratic Return",
                                               labels={'value': 'Cum Residual Return', 'index': 'Date'})
                            fig_line.update_traces(line=dict(width=2))
                            st.plotly_chart(fig_line, use_container_width=True)
                        
                        st.divider()
                        
                        if score > 0.5:
                            st.success(f"**ğŸ”¥ High Impact:** ì‹¤ì  ë°œí‘œê°€ ì´ ì¢…ëª©ì˜ ë³€ë™ì„± ëŒ€ë¹„ ìˆ˜ìµ íš¨ìœ¨ì„ í¬ê²Œ ë†’ì—¬ì¤ë‹ˆë‹¤. (Delta: +{score:.2f})")
                        elif score < 0.1:
                            st.warning(f"**ğŸ›¡ï¸ Low Impact:** ì‹¤ì  ë°œí‘œë¥¼ ì œì™¸í•´ë„ íš¨ìœ¨ì„± ì°¨ì´ê°€ ê±°ì˜ ì—†ìŠµë‹ˆë‹¤.")
                            
                    else:
                        st.error("ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨ (Market/Stock)")
                        
                except Exception as e:
                    st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

